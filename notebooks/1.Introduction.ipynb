{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65d0198a-b8b5-437f-b9a8-86f8acfe091e",
   "metadata": {},
   "source": [
    "# Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1449822-741f-4601-8a3b-5ccfbd4deab2",
   "metadata": {},
   "source": [
    "We'll be using OpenAI's embeddings for this course so make sure that you've set up a `OPENAI_API_KEY` variable in your shell so that you can run the commands easily out of the box.\n",
    "\n",
    "Before starting this part, make sure that you have ran the `setup.py` file so that we have a lancedb db that is populated with the first 100 rows of the ms-marco dataset.\n",
    "\n",
    "**Depending on the internet, this might take a while so do make sure that you have completed this step before the workshop**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6e75d3-8813-4731-8024-5574dc3e49f7",
   "metadata": {},
   "source": [
    "# Systematically Improve Your RAG\n",
    "\n",
    "In this portion, we'll learn how to make data driven decisions using a set of metrics that we can take advantage of to quickly compare different implementations/systems as well as to diagnose potential problems with our RAG application\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9979970-473e-4253-adbc-db32c555ec5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 9510.89it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 24.73it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 33.78it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:05<00:00,  1.90it/s]\n"
     ]
    }
   ],
   "source": [
    "from lib.data import get_labels\n",
    "from lib.query import full_text_search, semantic_search, hybrid_search\n",
    "from lib.eval import score\n",
    "from lib.models import EmbeddedPassage\n",
    "from lib.db import get_table\n",
    "import pandas as pd\n",
    "import lancedb\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "db = lancedb.connect(\"../lance\")\n",
    "\n",
    "candidates = {\n",
    "    \"Semantic Search\": semantic_search,\n",
    "    \"Full Text Search\": full_text_search,\n",
    "    \"Hybrid Search\": hybrid_search,\n",
    "}\n",
    "\n",
    "test_data = get_labels(\"../data/queries_single_label.jsonl\")[:10]\n",
    "table = get_table(db, \"ms_marco\", EmbeddedPassage)\n",
    "\n",
    "# Run test_data against candidates\n",
    "results = {}\n",
    "\n",
    "for candidate, search_fn in candidates.items():\n",
    "    search_results = search_fn(table, test_data, 25)\n",
    "    evaluation_metrics = [\n",
    "        score(retrieved_chunk_ids, query[\"selected_chunk_id\"])\n",
    "        for retrieved_chunk_ids, query in zip(search_results, test_data)\n",
    "    ]\n",
    "    results[candidate] = pd.DataFrame(evaluation_metrics).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fbbd4ac-6c58-4081-93e3-c94948b5a06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+--------------------+-----------------+\n",
      "|           |   Semantic Search |   Full Text Search |   Hybrid Search |\n",
      "+===========+===================+====================+=================+\n",
      "| mrr@3     |               0.5 |               0.25 |            0.38 |\n",
      "+-----------+-------------------+--------------------+-----------------+\n",
      "| mrr@5     |               0.5 |               0.34 |            0.46 |\n",
      "+-----------+-------------------+--------------------+-----------------+\n",
      "| mrr@10    |               0.5 |               0.36 |            0.46 |\n",
      "+-----------+-------------------+--------------------+-----------------+\n",
      "| mrr@15    |               0.5 |               0.37 |            0.46 |\n",
      "+-----------+-------------------+--------------------+-----------------+\n",
      "| mrr@25    |               0.5 |               0.37 |            0.46 |\n",
      "+-----------+-------------------+--------------------+-----------------+\n",
      "| recall@3  |               1   |               0.4  |            0.7  |\n",
      "+-----------+-------------------+--------------------+-----------------+\n",
      "| recall@5  |               1   |               0.8  |            1    |\n",
      "+-----------+-------------------+--------------------+-----------------+\n",
      "| recall@10 |               1   |               0.9  |            1    |\n",
      "+-----------+-------------------+--------------------+-----------------+\n",
      "| recall@15 |               1   |               1    |            1    |\n",
      "+-----------+-------------------+--------------------+-----------------+\n",
      "| recall@25 |               1   |               1    |            1    |\n",
      "+-----------+-------------------+--------------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "# Convert the dictionary to a DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Print the table\n",
    "print(tabulate(df.round(2), headers=\"keys\", tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2d7bf9-2384-4fc5-a54f-597d691ec74d",
   "metadata": {},
   "source": [
    "# Data Ingestion\n",
    "\n",
    "Let's start by looking how we can ingest some data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e94dd0f-9fdf-4637-941f-d3b682006e18",
   "metadata": {},
   "source": [
    "## LanceDB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed516cc-4dcd-4f66-b6fc-2af49a52ef0d",
   "metadata": {},
   "source": [
    "In this section, we'll be showing you can create a lancedb database, define a new table based off a Pydantic Schema, ingest some data AND perform semantic search and full text search in under 40 lines of code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5bb444a7-071f-48f6-8d2a-f1fe83a9f2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-06-10T01:18:23Z WARN  lance::dataset] No existing dataset at /Users/ivanleo/Documents/rag-ws/notebooks/lance-db/sample_table.lance, it will be created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Semantic) text: The Capital of France is Paris, vector: [0.026060976088047028, 0.020672272890806198], distance: 504.826\n",
      "\n",
      "(Semantic) text: Twitter is a popular web application, vector: [0.004910335876047611, -0.04718632996082306], distance: 506.344\n",
      "\n",
      "(Semantic) text: How long do you need for sydney and surrounding areas, vector: [0.009041019715368748, 0.02217705175280571], distance: 507.425\n",
      "\n",
      "(Full Text Search) text: The Capital of France is Paris, vector: [0.026060976088047028, 0.020672272890806198], distance: 0.892\n",
      "\n",
      "(Full Text Search) text: How long do you need for sydney and surrounding areas, vector: [0.009041019715368748, 0.02217705175280571], distance: 1.605\n",
      "\n",
      "(Full Text Search) text: Twitter is a popular web application, vector: [0.004910335876047611, -0.04718632996082306], distance: 1.806\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import lancedb\n",
    "from lancedb.pydantic import LanceModel, Vector\n",
    "from lancedb.embeddings import get_registry\n",
    "import numpy as np\n",
    "\n",
    "# Connect to the database\n",
    "db = lancedb.connect(\"./lance-db\")\n",
    "\n",
    "# Configure our Database Schema\n",
    "func = get_registry().get(\"openai\").create(name=\"text-embedding-3-small\")\n",
    "\n",
    "\n",
    "class Entry(LanceModel):\n",
    "    vector: Vector(func.ndims()) = func.VectorField(default=None)\n",
    "    text: str = func.SourceField()\n",
    "\n",
    "\n",
    "table = db.create_table(\"sample_table\", schema=Entry, mode=\"overwrite\")\n",
    "\n",
    "# Ingest data into our database\n",
    "sample_data = [\n",
    "    \"The Capital of France is Paris\",\n",
    "    \"How long do you need for sydney and surrounding areas\",\n",
    "    \"Twitter is a popular web application\",\n",
    "]\n",
    "\n",
    "table.add([Entry(text=text) for text in sample_data])\n",
    "\n",
    "table.create_fts_index(\"text\", replace=True)\n",
    "\n",
    "# Vector Search\n",
    "results = table.search(np.random.random((1536))).limit(10).to_list()\n",
    "\n",
    "for result in results:\n",
    "    print(\n",
    "        f\"(Semantic) text: {result['text']}, vector: {result['vector'][:2]}, distance: {round(result['_distance'],3)}\\n\"\n",
    "    )\n",
    "\n",
    "# Vector Search\n",
    "results = table.search(\"What's a good place to visit in France?\").limit(10).to_list()\n",
    "\n",
    "for result in results:\n",
    "    print(\n",
    "        f\"(Full Text Search) text: {result['text']}, vector: {result['vector'][:2]}, distance: {round(result['_distance'],3)}\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d541735b-7297-48d3-a2bd-381026db3e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vector</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.026060976, 0.020672273, 0.017380906, 0.0145...</td>\n",
       "      <td>The Capital of France is Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.00904102, 0.022177052, 0.06920571, 0.011817...</td>\n",
       "      <td>How long do you need for sydney and surroundin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.004910336, -0.04718633, -0.018725358, 0.030...</td>\n",
       "      <td>Twitter is a popular web application</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              vector  \\\n",
       "0  [0.026060976, 0.020672273, 0.017380906, 0.0145...   \n",
       "1  [0.00904102, 0.022177052, 0.06920571, 0.011817...   \n",
       "2  [0.004910336, -0.04718633, -0.018725358, 0.030...   \n",
       "\n",
       "                                                text  \n",
       "0                     The Capital of France is Paris  \n",
       "1  How long do you need for sydney and surroundin...  \n",
       "2               Twitter is a popular web application  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a6e557-bff1-453b-9f8e-376a6e947349",
   "metadata": {},
   "source": [
    "### Search\n",
    "\n",
    "What is Full Text Search, Semantic Search and Hybrid Search? Why would we prefer one over the other?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d18c02-2533-4998-9bed-b7a48d6da73e",
   "metadata": {},
   "source": [
    "#### Full Text Search\n",
    "\n",
    "We take a bunch of sentences, process them into some searchable form and then that allows us to find sentences/documents which are closest to a user query.\n",
    "\n",
    "**We are doing the search on the whole sentence, or some tokens generated from the text itself**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fb8e399-f8fc-4d0f-b5f4-5e01b6909024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results for query 'Sea Shells':\n",
      ">> She sells sea shells by the sea shore.\n"
     ]
    }
   ],
   "source": [
    "# List of sample sentences to choose from\n",
    "sentences = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"All good things come to those who wait.\",\n",
    "    \"She sells sea shells by the sea shore.\",\n",
    "    \"He ran out of money, so he had to stop playing poker.\",\n",
    "    \"They got there early, and they got really good seats.\",\n",
    "    \"There were white out conditions in the town; subsequently, the roads were impassable.\",\n",
    "    \"The sky is clear; the stars are twinkling.\",\n",
    "    \"The book is in front of the table.\",\n",
    "    \"A song can make or ruin a person’s day if they let it get to them.\",\n",
    "]\n",
    "\n",
    "\n",
    "def search_sentences(query):\n",
    "    \"\"\"Simple full text search in predefined sentences\"\"\"\n",
    "    results = [sentence for sentence in sentences if query.lower() in sentence.lower()]\n",
    "    return results\n",
    "\n",
    "\n",
    "# Example usage\n",
    "query = \"Sea Shells\"\n",
    "found_sentences = search_sentences(query)\n",
    "print(\"Search results for query '{}':\".format(query))\n",
    "for sentence in found_sentences:\n",
    "    print(f\">> {sentence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67df3d6-b7a3-4c71-a479-60c2fb6d0179",
   "metadata": {},
   "source": [
    "#### Semantic Search\n",
    "\n",
    "To do Semantic Search, we need a function that converts each sentence into a list of numbers known as a vector. Each number in this list has some semantic meaning, so two lists that have numbers that are closer are considered to be semantically similarly ( have the same meaning )\n",
    "\n",
    "We take our bunch of sentences, convert them to these list of numbers and store them somewhere. Whenever we have a user query, we then convert it to a vector using the same function and find the vector that's the most similar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b19f4bb9-724e-49a2-8c13-e64dabc379be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source >> [0.2, 0.1, 0.7]\n",
      "==========\n",
      "[1.00, 0.00, 0.50] - 0.669\n",
      "[0.00, 1.00, 0.50] - 0.548\n",
      "[0.50, 0.50, 0.00] - 0.289\n",
      "[0.00, 0.00, 1.00] - 0.953\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Define some sample vectors\n",
    "vectors = np.array([[1, 0, 0.5], [0, 1, 0.5], [0.5, 0.5, 0], [0, 0, 1]])\n",
    "\n",
    "\n",
    "# Define a simple function to perform vector search\n",
    "def vector_search(query_vector):\n",
    "    \"\"\"Perform a cosine similarity search between the query vector and predefined vectors\"\"\"\n",
    "    similarities = cosine_similarity([query_vector], vectors)\n",
    "    return similarities[0]\n",
    "\n",
    "\n",
    "# Example usage\n",
    "query_vector = [0.2, 0.1, 0.7]\n",
    "similarities = vector_search(query_vector)\n",
    "\n",
    "print(f\"Source >> {query_vector}\")\n",
    "print(\"==========\")\n",
    "\n",
    "for similarity, vector in zip(similarities, vectors):\n",
    "    formatted_vector = \", \".join(f\"{num:.2f}\" for num in vector)\n",
    "    print(f\"[{formatted_vector}] - {round(similarity,3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fa7957-833e-4f90-9272-342f7bb231f9",
   "metadata": {},
   "source": [
    "#### Why can't we just use Semantic Search - aren't embeddings all you need?\n",
    "\n",
    "Each search function has its own unique advantage\n",
    "\n",
    "- Semantic Search helps to find similar sentences without considering just keyword match\n",
    "- Text search helps us to identify entries that are using similar accronyms or are making references to specific people/places that semantic search might not catch\n",
    "\n",
    "Using a variety of search functions helps us to cast a wider net and have a higher chance of finding the entries we want.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d17938c-344d-49e0-9591-ec326d4ab8bd",
   "metadata": {},
   "source": [
    "#### Data Validation\n",
    "\n",
    "Why bother using Pydantic?\n",
    "\n",
    "- Data Validation that works out of the box with Vanilla Python\n",
    "- Insane Performance with the rust rewrite\n",
    "- Easy to customise and used by thousands of companies ( ~ 70M downloads per month for a reason )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76b18220-75a1-4d40-ab94-c489acfe5cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123\n",
      "{'id': 123, 'name': 'John Doe', 'signup_ts': datetime.datetime(2019, 6, 1, 12, 22), 'tastes': {'wine': 9, 'cheese': 7, 'cabbage': 1}}\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from pydantic import BaseModel, PositiveInt\n",
    "\n",
    "\n",
    "class User(BaseModel):\n",
    "    id: int\n",
    "    name: str = \"John Doe\"\n",
    "    signup_ts: datetime | None\n",
    "    tastes: dict[str, PositiveInt]\n",
    "\n",
    "\n",
    "external_data = {\n",
    "    \"id\": 123,\n",
    "    \"signup_ts\": \"2019-06-01 12:22\",\n",
    "    \"tastes\": {\n",
    "        \"wine\": 9,\n",
    "        b\"cheese\": 7,\n",
    "        \"cabbage\": \"1\",\n",
    "    },\n",
    "}\n",
    "\n",
    "user = User(**external_data)\n",
    "\n",
    "print(user.id)\n",
    "print(user.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e1b872-e516-4664-b6ac-310b58aebe92",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "Now that we've seen how easy it is to get started with LanceDB, we can start focusing on some of the most common problems that we'd face when ingesting data\n",
    "\n",
    "1. How do I store metadata?\n",
    "2. How can I compute some derived fields from my text chunks\n",
    "3. How does filtering of results work?\n",
    "4. How can I do deduplication on my data so that I don't have duplicate chunked text\n",
    "\n",
    "In the next few examples, we'll show you guys how to perform these basic operations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4c0144-dcdf-4c4f-855d-81f695cec7c9",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Run this command before proceeding with the exercises. The exercises should be done in order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0fa663c0-d203-4a28-9096-cdd330e94735",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../data/tools.json\", \"r\") as file:\n",
    "    data = json.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2345e436-a8d4-4f20-9ed2-483aeb82d65f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Hammer',\n",
       "  'description': 'A tool with a heavy metal head mounted at right angles at the end of a handle, used for jobs such as breaking things and driving in nails.',\n",
       "  'category': 'Hand Tool'},\n",
       " {'name': 'Screwdriver',\n",
       "  'description': 'A tool with a flattened, cross-shaped, or star-shaped tip that fits into the head of a screw to turn it.',\n",
       "  'category': 'Hand Tool'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b93b7bd-75db-4644-9f32-459d4faaa1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = lancedb.connect(\"./lance-db\")\n",
    "\n",
    "# Delete all tables in db\n",
    "for table in db.table_names():\n",
    "    db.drop_table(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de87e9f6-f3db-46d8-95ac-e16e46897c6a",
   "metadata": {},
   "source": [
    "### Adding metadata\n",
    "\n",
    "Try to create table which has information on the name, description and category of the item. Make sure to also embed the description using the `OpenAI` embedding function text-embedding-3-small model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9b4894a5-3f2d-45e7-90ae-1762ab1dc369",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-05-28T03:11:07Z WARN  lance::dataset] No existing dataset at /Users/ivanleo/Documents/rag-ws/notebooks/lance-db/tool_v1.lance, it will be created\n"
     ]
    }
   ],
   "source": [
    "# Create the Pydantic Schema\n",
    "\n",
    "func = get_registry().get(\"openai\").create(name=\"text-embedding-3-small\")\n",
    "\n",
    "\n",
    "class Tool(LanceModel):\n",
    "    vector: Vector(func.ndims()) = func.VectorField()\n",
    "    description: str = func.SourceField()\n",
    "    name: str\n",
    "    category: str\n",
    "\n",
    "\n",
    "tool_table = db.create_table(\"tool_v1\", schema=Tool, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e68c5c52-b942-4b62-8095-053a88e18f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_table.add(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56a32c16-35c6-480c-90ef-cbba4ecc9a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vector</th>\n",
       "      <th>description</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.02942855, 0.047012717, 0.004617972, -0.0125...</td>\n",
       "      <td>A tool with a heavy metal head mounted at righ...</td>\n",
       "      <td>Hammer</td>\n",
       "      <td>Hand Tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.018697312, 0.015099513, -0.047086194, -0.01...</td>\n",
       "      <td>A tool with a flattened, cross-shaped, or star...</td>\n",
       "      <td>Screwdriver</td>\n",
       "      <td>Hand Tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.03568479, 0.013477032, 0.0101103475, -0.01...</td>\n",
       "      <td>A power tool fitted with a cutting tool attach...</td>\n",
       "      <td>Electric Drill</td>\n",
       "      <td>Power Tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.02803261, 0.024098208, -0.026885075, -0.021...</td>\n",
       "      <td>A tool used for gripping and turning nuts, bol...</td>\n",
       "      <td>Wrench</td>\n",
       "      <td>Hand Tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.02052933, 0.014397344, -0.034926675, -0.013...</td>\n",
       "      <td>A hand tool used to hold objects firmly, possi...</td>\n",
       "      <td>Pliers</td>\n",
       "      <td>Hand Tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[-0.00037332025, 0.033678483, -0.03620599, -0....</td>\n",
       "      <td>A power-saw using a toothed or abrasive disc o...</td>\n",
       "      <td>Circular Saw</td>\n",
       "      <td>Power Tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.020676186, 0.032748703, 0.0079361405, -0.01...</td>\n",
       "      <td>A flexible ruler used to measure size or dista...</td>\n",
       "      <td>Tape Measure</td>\n",
       "      <td>Measuring Tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.06171664, 0.04006746, -0.0073134657, -0.004...</td>\n",
       "      <td>A tool with a characteristically shaped cuttin...</td>\n",
       "      <td>Chisel</td>\n",
       "      <td>Hand Tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[-0.024902405, 0.054924037, 0.0053345207, -0.0...</td>\n",
       "      <td>An instrument designed to indicate whether a s...</td>\n",
       "      <td>Level</td>\n",
       "      <td>Measuring Tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.014727382, 0.035678905, -0.026631918, -0.03...</td>\n",
       "      <td>A power tool used for cutting arbitrary curves...</td>\n",
       "      <td>Jigsaw</td>\n",
       "      <td>Power Tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[0.034014557, 0.025256732, 4.1296016e-06, -0.0...</td>\n",
       "      <td>A tool used to drive bolts and screws with hex...</td>\n",
       "      <td>Allen Wrench</td>\n",
       "      <td>Hand Tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[0.013575321, 0.014992961, -0.020640839, -0.00...</td>\n",
       "      <td>A wrench with a socket attached at one end, us...</td>\n",
       "      <td>Socket Wrench</td>\n",
       "      <td>Hand Tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0.0193977, 0.04276311, -0.040092036, -0.03646...</td>\n",
       "      <td>A fine-toothed saw, originally and mainly made...</td>\n",
       "      <td>Hacksaw</td>\n",
       "      <td>Hand Tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[0.0082187895, 0.0144082485, -0.010188434, -0....</td>\n",
       "      <td>An electronic measuring instrument that combin...</td>\n",
       "      <td>Multimeter</td>\n",
       "      <td>Measuring Tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[0.053213764, 0.004497374, -0.060332965, -0.05...</td>\n",
       "      <td>A hand tool used in soldering, which supplies ...</td>\n",
       "      <td>Soldering Iron</td>\n",
       "      <td>Hand Tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[-0.017129114, 0.043062504, -0.032209706, 0.01...</td>\n",
       "      <td>A handheld power tool used for grinding (abras...</td>\n",
       "      <td>Angle Grinder</td>\n",
       "      <td>Power Tool</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               vector  \\\n",
       "0   [0.02942855, 0.047012717, 0.004617972, -0.0125...   \n",
       "1   [0.018697312, 0.015099513, -0.047086194, -0.01...   \n",
       "2   [-0.03568479, 0.013477032, 0.0101103475, -0.01...   \n",
       "3   [0.02803261, 0.024098208, -0.026885075, -0.021...   \n",
       "4   [0.02052933, 0.014397344, -0.034926675, -0.013...   \n",
       "5   [-0.00037332025, 0.033678483, -0.03620599, -0....   \n",
       "6   [0.020676186, 0.032748703, 0.0079361405, -0.01...   \n",
       "7   [0.06171664, 0.04006746, -0.0073134657, -0.004...   \n",
       "8   [-0.024902405, 0.054924037, 0.0053345207, -0.0...   \n",
       "9   [0.014727382, 0.035678905, -0.026631918, -0.03...   \n",
       "10  [0.034014557, 0.025256732, 4.1296016e-06, -0.0...   \n",
       "11  [0.013575321, 0.014992961, -0.020640839, -0.00...   \n",
       "12  [0.0193977, 0.04276311, -0.040092036, -0.03646...   \n",
       "13  [0.0082187895, 0.0144082485, -0.010188434, -0....   \n",
       "14  [0.053213764, 0.004497374, -0.060332965, -0.05...   \n",
       "15  [-0.017129114, 0.043062504, -0.032209706, 0.01...   \n",
       "\n",
       "                                          description            name  \\\n",
       "0   A tool with a heavy metal head mounted at righ...          Hammer   \n",
       "1   A tool with a flattened, cross-shaped, or star...     Screwdriver   \n",
       "2   A power tool fitted with a cutting tool attach...  Electric Drill   \n",
       "3   A tool used for gripping and turning nuts, bol...          Wrench   \n",
       "4   A hand tool used to hold objects firmly, possi...          Pliers   \n",
       "5   A power-saw using a toothed or abrasive disc o...    Circular Saw   \n",
       "6   A flexible ruler used to measure size or dista...    Tape Measure   \n",
       "7   A tool with a characteristically shaped cuttin...          Chisel   \n",
       "8   An instrument designed to indicate whether a s...           Level   \n",
       "9   A power tool used for cutting arbitrary curves...          Jigsaw   \n",
       "10  A tool used to drive bolts and screws with hex...    Allen Wrench   \n",
       "11  A wrench with a socket attached at one end, us...   Socket Wrench   \n",
       "12  A fine-toothed saw, originally and mainly made...         Hacksaw   \n",
       "13  An electronic measuring instrument that combin...      Multimeter   \n",
       "14  A hand tool used in soldering, which supplies ...  Soldering Iron   \n",
       "15  A handheld power tool used for grinding (abras...   Angle Grinder   \n",
       "\n",
       "          category  \n",
       "0        Hand Tool  \n",
       "1        Hand Tool  \n",
       "2       Power Tool  \n",
       "3        Hand Tool  \n",
       "4        Hand Tool  \n",
       "5       Power Tool  \n",
       "6   Measuring Tool  \n",
       "7        Hand Tool  \n",
       "8   Measuring Tool  \n",
       "9       Power Tool  \n",
       "10       Hand Tool  \n",
       "11       Hand Tool  \n",
       "12       Hand Tool  \n",
       "13  Measuring Tool  \n",
       "14       Hand Tool  \n",
       "15      Power Tool  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_table.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19189ad1-6649-45a6-baf5-f3e9db217dcd",
   "metadata": {},
   "source": [
    "### Computing a field\n",
    "\n",
    "Let's now try to compute a chunk_id which identifies a unique description and name using the `hashlib` library in python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1f9ef27-654f-4043-9e96-a95fda2fd043",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-05-28T03:11:08Z WARN  lance::dataset] No existing dataset at /Users/ivanleo/Documents/rag-ws/notebooks/lance-db/tool_v2.lance, it will be created\n"
     ]
    }
   ],
   "source": [
    "# Create the Pydantic Schema\n",
    "\n",
    "func = get_registry().get(\"openai\").create(name=\"text-embedding-3-small\")\n",
    "\n",
    "\n",
    "class Tool(LanceModel):\n",
    "    vector: Vector(func.ndims()) = func.VectorField()\n",
    "    description: str = func.SourceField()\n",
    "    name: str\n",
    "    category: str\n",
    "    tool_id: str\n",
    "\n",
    "\n",
    "tool_table = db.create_table(\"tool_v2\", schema=Tool, mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7fb73f9a-f935-4697-9478-c0fa8521bf26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vector</th>\n",
       "      <th>description</th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>tool_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.029243259, 0.046320148, 0.0031912285, -0.00...</td>\n",
       "      <td>A tool with a heavy metal head mounted at righ...</td>\n",
       "      <td>Hammer</td>\n",
       "      <td>Hand Tool</td>\n",
       "      <td>5127eb88579d6565b794833acf0eff6e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.018722245, 0.01513522, -0.047092352, -0.010...</td>\n",
       "      <td>A tool with a flattened, cross-shaped, or star...</td>\n",
       "      <td>Screwdriver</td>\n",
       "      <td>Hand Tool</td>\n",
       "      <td>18ffc6ead466b6e270e8a970544510d3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.03569433, 0.013480635, 0.010113051, -0.019...</td>\n",
       "      <td>A power tool fitted with a cutting tool attach...</td>\n",
       "      <td>Electric Drill</td>\n",
       "      <td>Power Tool</td>\n",
       "      <td>ad1d1aac2c439006635c48d6969d2a8f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.028033728, 0.02412259, -0.026932988, -0.021...</td>\n",
       "      <td>A tool used for gripping and turning nuts, bol...</td>\n",
       "      <td>Wrench</td>\n",
       "      <td>Hand Tool</td>\n",
       "      <td>bbf94b44b5866f023b2b8b5491657dd3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.02175587, 0.013911997, -0.03692618, -0.0119...</td>\n",
       "      <td>A hand tool used to hold objects firmly, possi...</td>\n",
       "      <td>Pliers</td>\n",
       "      <td>Hand Tool</td>\n",
       "      <td>36d03bc35bdddd89da298675e5c0cd73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[-0.0005456097, 0.033061855, -0.03701373, -0.0...</td>\n",
       "      <td>A power-saw using a toothed or abrasive disc o...</td>\n",
       "      <td>Circular Saw</td>\n",
       "      <td>Power Tool</td>\n",
       "      <td>61051798477a715f7e2e09df8880a8ee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.020711862, 0.03277381, 0.007930988, -0.0128...</td>\n",
       "      <td>A flexible ruler used to measure size or dista...</td>\n",
       "      <td>Tape Measure</td>\n",
       "      <td>Measuring Tool</td>\n",
       "      <td>8bd1313982c2bd9313f1ac304ac43f8b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.061667863, 0.0399984, -0.0072744344, -0.004...</td>\n",
       "      <td>A tool with a characteristically shaped cuttin...</td>\n",
       "      <td>Chisel</td>\n",
       "      <td>Hand Tool</td>\n",
       "      <td>d65a66bc9595fa8a1247bcdcbe5a0a37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[-0.024902405, 0.054924037, 0.0053345207, -0.0...</td>\n",
       "      <td>An instrument designed to indicate whether a s...</td>\n",
       "      <td>Level</td>\n",
       "      <td>Measuring Tool</td>\n",
       "      <td>356a50889baebb01c83c2b33eba1187c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.014716265, 0.03568, -0.026632737, -0.033990...</td>\n",
       "      <td>A power tool used for cutting arbitrary curves...</td>\n",
       "      <td>Jigsaw</td>\n",
       "      <td>Power Tool</td>\n",
       "      <td>dda7672a25896af487fef054e3775f2a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              vector  \\\n",
       "0  [0.029243259, 0.046320148, 0.0031912285, -0.00...   \n",
       "1  [0.018722245, 0.01513522, -0.047092352, -0.010...   \n",
       "2  [-0.03569433, 0.013480635, 0.010113051, -0.019...   \n",
       "3  [0.028033728, 0.02412259, -0.026932988, -0.021...   \n",
       "4  [0.02175587, 0.013911997, -0.03692618, -0.0119...   \n",
       "5  [-0.0005456097, 0.033061855, -0.03701373, -0.0...   \n",
       "6  [0.020711862, 0.03277381, 0.007930988, -0.0128...   \n",
       "7  [0.061667863, 0.0399984, -0.0072744344, -0.004...   \n",
       "8  [-0.024902405, 0.054924037, 0.0053345207, -0.0...   \n",
       "9  [0.014716265, 0.03568, -0.026632737, -0.033990...   \n",
       "\n",
       "                                         description            name  \\\n",
       "0  A tool with a heavy metal head mounted at righ...          Hammer   \n",
       "1  A tool with a flattened, cross-shaped, or star...     Screwdriver   \n",
       "2  A power tool fitted with a cutting tool attach...  Electric Drill   \n",
       "3  A tool used for gripping and turning nuts, bol...          Wrench   \n",
       "4  A hand tool used to hold objects firmly, possi...          Pliers   \n",
       "5  A power-saw using a toothed or abrasive disc o...    Circular Saw   \n",
       "6  A flexible ruler used to measure size or dista...    Tape Measure   \n",
       "7  A tool with a characteristically shaped cuttin...          Chisel   \n",
       "8  An instrument designed to indicate whether a s...           Level   \n",
       "9  A power tool used for cutting arbitrary curves...          Jigsaw   \n",
       "\n",
       "         category                           tool_id  \n",
       "0       Hand Tool  5127eb88579d6565b794833acf0eff6e  \n",
       "1       Hand Tool  18ffc6ead466b6e270e8a970544510d3  \n",
       "2      Power Tool  ad1d1aac2c439006635c48d6969d2a8f  \n",
       "3       Hand Tool  bbf94b44b5866f023b2b8b5491657dd3  \n",
       "4       Hand Tool  36d03bc35bdddd89da298675e5c0cd73  \n",
       "5      Power Tool  61051798477a715f7e2e09df8880a8ee  \n",
       "6  Measuring Tool  8bd1313982c2bd9313f1ac304ac43f8b  \n",
       "7       Hand Tool  d65a66bc9595fa8a1247bcdcbe5a0a37  \n",
       "8  Measuring Tool  356a50889baebb01c83c2b33eba1187c  \n",
       "9      Power Tool  dda7672a25896af487fef054e3775f2a  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "encoded_chunks = []\n",
    "for row in data:\n",
    "    name_and_description = f\"{row['description']}-{row['name']}\"\n",
    "    tool_id = hashlib.md5(name_and_description.encode()).hexdigest()\n",
    "    encoded_chunks.append({**row, \"tool_id\": tool_id})\n",
    "\n",
    "tool_table.add(encoded_chunks)\n",
    "tool_table.to_pandas()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d839bfcf-a3c5-43e4-9b3b-b32eca8ef6d2",
   "metadata": {},
   "source": [
    "### Filtering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042fc286-f4d4-4668-9da7-b75372bd715e",
   "metadata": {},
   "source": [
    "Now that we've indexed our data inside the field, let's try to retrieve all of the tools which have the category Hand Tool (Note here that we have prefilter=True which allows us to ensure we get the number of elements that we want in the end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe8ff36b-7be0-4703-80ed-e0c2b6a3b609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.81 ms, sys: 3.5 ms, total: 8.31 ms\n",
      "Wall time: 4.81 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hammer</td>\n",
       "      <td>A tool with a heavy metal head mounted at righ...</td>\n",
       "      <td>Hand Tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Screwdriver</td>\n",
       "      <td>A tool with a flattened, cross-shaped, or star...</td>\n",
       "      <td>Hand Tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wrench</td>\n",
       "      <td>A tool used for gripping and turning nuts, bol...</td>\n",
       "      <td>Hand Tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pliers</td>\n",
       "      <td>A hand tool used to hold objects firmly, possi...</td>\n",
       "      <td>Hand Tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chisel</td>\n",
       "      <td>A tool with a characteristically shaped cuttin...</td>\n",
       "      <td>Hand Tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Allen Wrench</td>\n",
       "      <td>A tool used to drive bolts and screws with hex...</td>\n",
       "      <td>Hand Tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Socket Wrench</td>\n",
       "      <td>A wrench with a socket attached at one end, us...</td>\n",
       "      <td>Hand Tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hacksaw</td>\n",
       "      <td>A fine-toothed saw, originally and mainly made...</td>\n",
       "      <td>Hand Tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Soldering Iron</td>\n",
       "      <td>A hand tool used in soldering, which supplies ...</td>\n",
       "      <td>Hand Tool</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name                                        description  \\\n",
       "0          Hammer  A tool with a heavy metal head mounted at righ...   \n",
       "1     Screwdriver  A tool with a flattened, cross-shaped, or star...   \n",
       "2          Wrench  A tool used for gripping and turning nuts, bol...   \n",
       "3          Pliers  A hand tool used to hold objects firmly, possi...   \n",
       "4          Chisel  A tool with a characteristically shaped cuttin...   \n",
       "5    Allen Wrench  A tool used to drive bolts and screws with hex...   \n",
       "6   Socket Wrench  A wrench with a socket attached at one end, us...   \n",
       "7         Hacksaw  A fine-toothed saw, originally and mainly made...   \n",
       "8  Soldering Iron  A hand tool used in soldering, which supplies ...   \n",
       "\n",
       "    category  \n",
       "0  Hand Tool  \n",
       "1  Hand Tool  \n",
       "2  Hand Tool  \n",
       "3  Hand Tool  \n",
       "4  Hand Tool  \n",
       "5  Hand Tool  \n",
       "6  Hand Tool  \n",
       "7  Hand Tool  \n",
       "8  Hand Tool  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tool_table = db.open_table(\"tool_v2\")\n",
    "tool_table.search().select([\"name\", \"description\", \"category\"]).where(\n",
    "    \"category='Hand Tool'\", prefilter=True\n",
    ").to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe76551-5f59-4e2f-92aa-3f24a35bfea3",
   "metadata": {},
   "source": [
    "Now that we've indexed a single column, let's try now returning rows that have the `Measuring Tool` and `Hand Tool` category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d899cc4a-1509-4bfa-ae92-492f34f24b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.98 ms, sys: 4.15 ms, total: 10.1 ms\n",
      "Wall time: 8.41 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hammer</td>\n",
       "      <td>A tool with a heavy metal head mounted at righ...</td>\n",
       "      <td>Hand Tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Screwdriver</td>\n",
       "      <td>A tool with a flattened, cross-shaped, or star...</td>\n",
       "      <td>Hand Tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wrench</td>\n",
       "      <td>A tool used for gripping and turning nuts, bol...</td>\n",
       "      <td>Hand Tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pliers</td>\n",
       "      <td>A hand tool used to hold objects firmly, possi...</td>\n",
       "      <td>Hand Tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tape Measure</td>\n",
       "      <td>A flexible ruler used to measure size or dista...</td>\n",
       "      <td>Measuring Tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chisel</td>\n",
       "      <td>A tool with a characteristically shaped cuttin...</td>\n",
       "      <td>Hand Tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Level</td>\n",
       "      <td>An instrument designed to indicate whether a s...</td>\n",
       "      <td>Measuring Tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Allen Wrench</td>\n",
       "      <td>A tool used to drive bolts and screws with hex...</td>\n",
       "      <td>Hand Tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Socket Wrench</td>\n",
       "      <td>A wrench with a socket attached at one end, us...</td>\n",
       "      <td>Hand Tool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hacksaw</td>\n",
       "      <td>A fine-toothed saw, originally and mainly made...</td>\n",
       "      <td>Hand Tool</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name                                        description  \\\n",
       "0         Hammer  A tool with a heavy metal head mounted at righ...   \n",
       "1    Screwdriver  A tool with a flattened, cross-shaped, or star...   \n",
       "2         Wrench  A tool used for gripping and turning nuts, bol...   \n",
       "3         Pliers  A hand tool used to hold objects firmly, possi...   \n",
       "4   Tape Measure  A flexible ruler used to measure size or dista...   \n",
       "5         Chisel  A tool with a characteristically shaped cuttin...   \n",
       "6          Level  An instrument designed to indicate whether a s...   \n",
       "7   Allen Wrench  A tool used to drive bolts and screws with hex...   \n",
       "8  Socket Wrench  A wrench with a socket attached at one end, us...   \n",
       "9        Hacksaw  A fine-toothed saw, originally and mainly made...   \n",
       "\n",
       "         category  \n",
       "0       Hand Tool  \n",
       "1       Hand Tool  \n",
       "2       Hand Tool  \n",
       "3       Hand Tool  \n",
       "4  Measuring Tool  \n",
       "5       Hand Tool  \n",
       "6  Measuring Tool  \n",
       "7       Hand Tool  \n",
       "8       Hand Tool  \n",
       "9       Hand Tool  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tool_table = db.open_table(\"tool_v2\")\n",
    "tool_table.search().select([\"name\", \"description\", \"category\"]).where(\n",
    "    \"category IN ('Hand Tool','Measuring Tool')\", prefilter=True\n",
    ").to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61afbaa4-98ee-4c21-8a62-254e7bf538ba",
   "metadata": {},
   "source": [
    "### Deduplication\n",
    "\n",
    "Now that we've ingested the data, we need to make sure we don't have any deduplication of data. To do so, we'll use a second set of tools in `tool_2.json` which has some overlapping entries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a7637f5-4e0a-48d7-a33b-5ba56c88da3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./tools_2.json\", \"r\") as file:\n",
    "    data_2 = json.loads(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28288ee4-2f2d-4e72-906f-fd08d44be5a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 7)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_table.count_rows(), len(data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25e6f321-40cb-4aaa-994f-f9c0ceae067c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_table = db.open_table(\"tool_v1\")\n",
    "tool_table.add(data_2)\n",
    "tool_table.count_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5de3b175-baa0-4a7b-aef7-54d486eaff9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_table = db.open_table(\"tool_v1\")\n",
    "tool_table.add(data_2)\n",
    "tool_table.count_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4b25c878-dbb9-45aa-bdf0-81144ac89fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "encoded_chunks = []\n",
    "for row in data_2:\n",
    "    name_and_description = f\"{row['description']}-{row['name']}\"\n",
    "    chunk_id = hashlib.md5(name_and_description.encode()).hexdigest()\n",
    "    encoded_chunks.append({**row, \"chunk_id\": chunk_id})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "62bb474a-0232-4e73-a323-247eaf300841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the Pydantic Schema\n",
    "\n",
    "func = get_registry().get(\"openai\").create(name=\"text-embedding-3-small\")\n",
    "\n",
    "\n",
    "class Tool(LanceModel):\n",
    "    vector: Vector(func.ndims()) = func.VectorField()\n",
    "    description: str = func.SourceField()\n",
    "    name: str\n",
    "    category: str\n",
    "    chunk_id: str\n",
    "\n",
    "\n",
    "tool_table = db.create_table(\"tool_v2\", schema=Tool, mode=\"overwrite\")\n",
    "\n",
    "encoded_chunks = []\n",
    "for row in data:\n",
    "    name_and_description = f\"{row['description']}-{row['name']}\"\n",
    "    chunk_id = hashlib.md5(name_and_description.encode()).hexdigest()\n",
    "    encoded_chunks.append({**row, \"chunk_id\": chunk_id})\n",
    "\n",
    "\n",
    "def get_duplicate_chunk_ids(encoded_chunks):\n",
    "    tool_table = db.open_table(\"tool_v2\")\n",
    "    ids = [item[\"chunk_id\"] for item in encoded_chunks]\n",
    "\n",
    "    formatted_filter = \", \".join([f\"'{id}'\" for id in ids])\n",
    "    return set(\n",
    "        tool_table.to_lance()\n",
    "        .to_table(filter=f\"chunk_id in ({formatted_filter})\", columns=[\"chunk_id\"])\n",
    "        .to_pandas()[\"chunk_id\"]\n",
    "    )\n",
    "\n",
    "\n",
    "def filter_duplicate_chunks(encoded_chunks, duplicate_ids):\n",
    "    return [item for item in encoded_chunks if item[\"chunk_id\"] not in duplicate_ids]\n",
    "\n",
    "\n",
    "duplicate_ids = get_duplicate_chunk_ids(encoded_chunks)\n",
    "filtered_chunks = filter_duplicate_chunks(encoded_chunks, duplicate_ids)\n",
    "\n",
    "if filtered_chunks:\n",
    "    tool_table.add(filtered_chunks)\n",
    "tool_table.count_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5272d615-e2e1-4273-80c6-6e3155e99c2e",
   "metadata": {},
   "source": [
    "Before we proceed, let's clean up the database that we used for this section and remove it from our computer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "165e1b8a-117c-4fb1-992d-5b48e927f1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.rmtree(\"./lance-db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a453b7-ee4e-404c-9beb-ae8120e41851",
   "metadata": {},
   "source": [
    "**Summary** : LanceDB provides an easy way to have FTS ( as a simple baseline ) and embedding search. It also handles batching and provides other functionality such as integrations with duckdb, arrow table and filtering out of the box.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da960f25-4d35-4a4e-bf97-fdc7a6b93f7d",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "The metrics you capture are specific to the use case that you have. In this notebook we'll walk through 3-4 different potential example use cases and why you might want different metrics at each step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fd83d9-df15-471e-ac7a-f492b79d82f0",
   "metadata": {},
   "source": [
    "## At K\n",
    "\n",
    "We need to report the size of the list of elements that we compute our metrics for. This is known as the `at k` value. For instance, if we calculated the precision of a list of 5 elements, we would say that our `precision@5` metric is `x`.\n",
    "\n",
    "This is important because k is often constrained by a business outcome and can help us determine how well our solution works\n",
    "\n",
    "Eg.\n",
    "\n",
    "- `k=5` : We'd like to display some recomended items based of a user query (Eg. Help me plan out a dinner with Jonathan next week -> Display 5 possible actions)\n",
    "- `k=10` : We have a small carousel with recomended items for a user to buy\n",
    "- `k=25` : We're using a re-ranker, is it filtering out the irrelevant chunks from the relevant chunks well?\n",
    "- `k=50` : We have a pipeline that fetches information for a model to respond with, are we fetching all relevant bits of information\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb291ac-9762-4876-bbd7-9b40f48b5642",
   "metadata": {},
   "source": [
    "## Quick Note\n",
    "\n",
    "Note that many of the metrics we'll show below work with binary labels - this means that we only have information on whether they are relevant or not. This is sufficient for most RAG applications since the model itself will be able to determine the relevance of the chunk relative to the user's query.\n",
    "\n",
    "As models improve, this will become less of a problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33ffd7e-c8dc-4f16-b110-a541dd344c5b",
   "metadata": {},
   "source": [
    "## Reciprocal Rank\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15475bfd-a4a3-4cfb-921e-6243a0d00994",
   "metadata": {},
   "source": [
    "Lists in python are going to be 0 indexed. The first element has a index of 0, the second has an index of 1 and so on.\n",
    "\n",
    "If our list is `[1,2,3,4]`, then\n",
    "\n",
    "- Index 0 : 1\n",
    "- Index 1 : 2\n",
    "- Index 2 : 3\n",
    "- Index 3 : 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02df5a2e-1fd1-4ad0-94e9-1690bc389d43",
   "metadata": {},
   "source": [
    "If we're using LLMs to generate search queries to identify potential actions that a user might want us to take, then we definitely want to make sure that we surface relevant results as early as possible. In other words, we want to make sure our index is as close to 0 as possible.\n",
    "\n",
    "> Which is a better result among the two lists of retrieved songs below? ( Note that 2 is the answer we want )\n",
    "\n",
    "- [0,1,2,3,4]\n",
    "- [0,1,3,4,2]\n",
    "\n",
    "Obviously if we're suggesting actions to the user, we want the first relevant action to be listed as early as possible! Therefore we'd prefer 1 over 2 in the example above because 2 is ordered earlier in the first case.\n",
    "\n",
    "A metric that works well for this is the Reciprocal Rank (RR).\n",
    "\n",
    "$$\n",
    "\\frac{1}{\\text{Index of first relevant item + 1}}\n",
    "$$\n",
    "\n",
    "We add 1 here so that we don't get a zero division error ( Since indexes start from 0 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5b5b223-9280-4aa4-a65b-374233bcb2c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.33, 0.2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rr(results, label):\n",
    "    return round(1 / (results.index(label) + 1), 2) if label in results else 0\n",
    "\n",
    "\n",
    "rr([0, 1, 2, 3, 4], 2), rr([0, 1, 3, 4, 2], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd0c6c5-9c4c-4099-9f0b-a3b931fd503f",
   "metadata": {},
   "source": [
    "This is an aggressive metric and once we get to an position of > 10, the value doesn't change much anymore. Most of the big changes happen at indexes < 10.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a4bdd21e-ddf5-40c2-afd1-60c9290f2899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0| 1.00 ---|(--0.50)\n",
      "            ↓\n",
      " 1|        0.50 ---|(--0.17)\n",
      "                   ↓\n",
      " 2|               0.33 ---|(--0.08)\n",
      "                          ↓\n",
      " 3|                      0.25 ---|(--0.05)\n",
      "                                 ↓\n",
      " 4|                             0.20 ---|(--0.03)\n",
      "                                        ↓\n",
      " 5|                                    0.17 ---|(--0.03)\n",
      "                                               ↓\n",
      " 6|                                           0.14 ---|(--0.02)\n",
      "                                                      ↓\n",
      " 7|                                                  0.12 ---|(--0.01)\n",
      "                                                             ↓\n",
      " 8|                                                         0.11 ---|(--0.01)\n",
      "                                                                    ↓\n",
      " 9|                                                                0.10\n"
     ]
    }
   ],
   "source": [
    "def get_rr_at_index(desired_index, length=20):\n",
    "    return rr([0 if i != desired_index else 1 for i in range(length)], 1)\n",
    "\n",
    "\n",
    "max_itrs = 10\n",
    "for i in range(max_itrs):\n",
    "    curr_rr = get_rr_at_index(i)\n",
    "    decrease = get_rr_at_index(i + 1) - get_rr_at_index(i) if i < max_itrs - 1 else 0\n",
    "    decrease_string = f\" ---|(-{decrease:.2f})\" if i < max_itrs - 1 else \"\"\n",
    "    print(f\"{i:2}| {' '*(7*i)}{curr_rr:.2f}{decrease_string}\")\n",
    "    if i < max_itrs - 1:\n",
    "        print(\"↓\".rjust(7 * (i + 1) + 6))\n",
    "    prev_rr = curr_rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3061e137-a8ce-4c7d-ae83-1a85dd6018a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.linspace(1, 15, 15)\n",
    "y = 1 / x\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.xlabel(\"First Relevant Item Index\")\n",
    "plt.ylabel(\"RR value\")\n",
    "plt.title(\"RR vs index\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "afdec5ac-40d0-4aa0-930e-e57015a8b461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.33, 0.2)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rr_multi(results, labels):\n",
    "    return max(\n",
    "        [\n",
    "            round(1 / (results.index(label) + 1), 2) if label in results else 0\n",
    "            for label in labels\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "rr_multi([0, 1, 2, 3, 5], [2, 4]), rr_multi([0, 1, 3, 4, 2], [2, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697ecf87-66af-49f1-9cec-a6595ca6a81d",
   "metadata": {},
   "source": [
    "When we have a group of different items and we take the average rr, we get the Mean Reciprocal Rank (MRR) which tells us the average position of the first relevant item in our retrieved results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bdf6bc-d1b7-4952-8cd5-e06b84490dca",
   "metadata": {},
   "source": [
    "## Recall\n",
    "\n",
    "Imagine that we're trying to do some Retrieval Augmented Generation and we're not getting good results - some of our vibe checks are failing. How can we now diagnose the issue and determine if it's our retrieval pipeline that's causing the issue?\n",
    "\n",
    "Well, recall is a great place to start!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "55e45ea8-128a-4843-8bce-7eef14e568d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_1 = [1, 2, 3, 4, 5]\n",
    "result_2 = [5, 2, 7, 8, 9]\n",
    "\n",
    "relevant_chunks = [4, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca055787-564f-4f34-87ae-c8c7999cf14b",
   "metadata": {},
   "source": [
    "> Why care about the number of retrieved relevant documents? Aren't we going to have a lot of irrelevant documents? => We care about the total number of retrieved relevant documents because we are confident that our model is able to sift through the provided sources. As model capabilities improve, this is quite a valid assumption ( See [Needle In A Haystack](https://arize.com/blog-course/the-needle-in-a-haystack-test-evaluating-the-performance-of-llm-rag-systems/) test )\n",
    "\n",
    "We're trying to ask a single question when we look at Recall - How many of my relevant documents were retrieved? It can be calculated by taking\n",
    "\n",
    "$$\n",
    "\\frac{\\text{Number of Relevant Documents retrieved}}{\\text{Total Number of relevant documents}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b3b4591a-e97a-4f26-a7d5-827b1064fe50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.5)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recall(results, relevant_chunks):\n",
    "    return sum([1 if chunk in results else 0 for chunk in relevant_chunks]) / len(\n",
    "        relevant_chunks\n",
    "    )\n",
    "\n",
    "\n",
    "recall(result_1, relevant_chunks), recall(result_2, relevant_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bb8809-ba00-4012-8915-8a74be63a30d",
   "metadata": {},
   "source": [
    "### What affects recall?\n",
    "\n",
    "#### Number of irrelevant items?\n",
    "\n",
    "Recall isn't affected by the number of irrelevant items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f3340099-e553-4510-a2a2-60e23ba4b100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.5)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_1 = [1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "result_2 = [1, 2, 3]\n",
    "\n",
    "relevant_chunks = [1, 2, 4, 10]\n",
    "\n",
    "# Which has a better recall?\n",
    "\n",
    "(\n",
    "    recall(result_1, relevant_chunks),\n",
    "    recall(result_2, relevant_chunks),\n",
    ")  # Recall is the same!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41d60a7-ed2c-4a0b-b5e4-6e01dd067afa",
   "metadata": {},
   "source": [
    "#### Ordering of Elements?\n",
    "\n",
    "Is Recall affected by the order of the elements? What happens if we jumble up the order of these items each time so that the elements are preserved BUT the ordering is not?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a4d14397-9270-46c8-8e4c-33b9e04e8fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 2, 3, 4] -> Recall: 1.0\n",
      "[0, 0, 0, 1, 2, 3, 0] -> Recall: 0.75\n",
      "[0, 0, 0, 1, 2, 0, 0] -> Recall: 0.5\n",
      "[0, 0, 0, 1, 0, 0, 0] -> Recall: 0.25\n",
      "[0, 0, 0, 0, 0, 0, 0] -> Recall: 0.0\n"
     ]
    }
   ],
   "source": [
    "r1 = [0, 0, 0, 1, 2, 3, 4]\n",
    "r2 = [0, 0, 0, 1, 2, 3, 0]\n",
    "r3 = [0, 0, 0, 1, 2, 0, 0]\n",
    "r4 = [0, 0, 0, 1, 0, 0, 0]\n",
    "r5 = [0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "relevant_chunks = [1, 2, 3, 4]\n",
    "\n",
    "retrieved_results = [r1, r2, r3, r4, r5]\n",
    "\n",
    "for retrieved_result in retrieved_results:\n",
    "    print(f\"{retrieved_result} -> Recall: {recall(retrieved_result,relevant_chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1fe75379-b82a-4c76-96c4-d86979f6b059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 4, 3, 2, 0] -> Recall: 1.0\n",
      "[1, 0, 0, 0, 2, 0, 3] -> Recall: 0.75\n",
      "[0, 0, 1, 0, 0, 2, 0] -> Recall: 0.5\n",
      "[0, 0, 0, 0, 0, 0, 1] -> Recall: 0.25\n",
      "[0, 0, 0, 0, 0, 0, 0] -> Recall: 0.0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "r1 = [0, 0, 0, 1, 2, 3, 4]\n",
    "r2 = [0, 0, 0, 1, 2, 3, 0]\n",
    "r3 = [0, 0, 0, 1, 2, 0, 0]\n",
    "r4 = [0, 0, 0, 1, 0, 0, 0]\n",
    "r5 = [0, 0, 0, 0, 0, 0, 0]\n",
    "\n",
    "relevant_chunks = [1, 2, 3, 4]\n",
    "\n",
    "retrieved_results = [r1, r2, r3, r4, r5]\n",
    "\n",
    "for retrieved_result in retrieved_results:\n",
    "    random.shuffle(retrieved_result)\n",
    "    print(f\"{retrieved_result} -> Recall: {recall(retrieved_result,relevant_chunks)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a9ad1b-734e-4207-af06-22dea191dbba",
   "metadata": {},
   "source": [
    "Therefore we can conclude that recall is **unaffected by the ordering of the items** and **unaffected by the number of irrelevant items**. It only cares about **the proportions of the relevant items that were retrieved**!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcb0da9-7ba8-4e83-8b27-81f36cf242e3",
   "metadata": {},
   "source": [
    "## Precision\n",
    "\n",
    "Say we're coding a new Agent which has access to 1000s of tools, how can we ensure we're giving our agent the right tools each time?\n",
    "\n",
    "For instance, say the user asks us a question of \"Help me find a time to meet with Daniel for dinner next week\" and we have the tools below\n",
    "\n",
    "Make a Calendar Appointment\n",
    "View Calendar\n",
    "Order a Coffee\n",
    "Send an Email\n",
    "Get the Weather\n",
    "Make a flight booking\n",
    "What are the most relevant tools that our model should return?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "77a48f3d-d861-40ad-bdd1-ca1c33c964bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    \"make_appointment\",\n",
    "    \"view_calendar\",\n",
    "    \"order_coffee\",\n",
    "    \"send_email\",\n",
    "    \"get_weather\",\n",
    "    \"make_flight_booking\",\n",
    "]\n",
    "\n",
    "candidate_1 = [\"order_coffee\", \"make_flight_booking\", \"get_weather\"]\n",
    "candidate_2 = [\"view_calendar\", \"make_flight_booking\", \"get_weather\"]\n",
    "candidate_3 = [\"view_calendar\", \"make_appointment\", \"send_email\"]\n",
    "\n",
    "relevant_tools = [\"view_calendar\", \"make_appointment\", \"send_email\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e18c0c-08e7-4693-ba7f-767876a80d65",
   "metadata": {},
   "source": [
    "How can we evaluate candidate_1, candidate_2 and candidate_3 so that we are able to rank them in terms of quality?\n",
    "\n",
    "We can use precision here to evaluate our models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "66f65de5-50e0-4791-b81a-32de10b6b236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['order_coffee', 'make_flight_booking', 'get_weather'] - 0.0\n",
      "['view_calendar', 'make_flight_booking', 'get_weather'] - 0.33\n",
      "['view_calendar', 'make_appointment', 'send_email'] - 1.0\n"
     ]
    }
   ],
   "source": [
    "def precision(retrieved_items, relevant_items):\n",
    "    return round(\n",
    "        sum([1 if item in relevant_items else 0 for item in retrieved_items])\n",
    "        / len(retrieved_items),\n",
    "        2,\n",
    "    )\n",
    "\n",
    "\n",
    "evaluated_items = [candidate_1, candidate_2, candidate_3]\n",
    "\n",
    "for item in evaluated_items:\n",
    "    print(f\"{item} - {precision(item,relevant_tools)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b7ae8a-fb26-4143-824f-033d5615a978",
   "metadata": {},
   "source": [
    "### What affects precision?\n",
    "\n",
    "#### Ordering of Elements?\n",
    "\n",
    "What happens if we randomly reorder the items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "62612f80-f412-4aab-99ad-d3bab077543b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['order_coffee', 'make_flight_booking', 'get_weather'] - 0.0\n",
      "['make_flight_booking', 'view_calendar', 'get_weather'] - 0.33\n",
      "['make_appointment', 'view_calendar', 'send_email'] - 1.0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "evaluated_items = [candidate_1, candidate_2, candidate_3]\n",
    "\n",
    "for item in evaluated_items:\n",
    "    random.shuffle(item)\n",
    "    print(f\"{item} - {precision(item,relevant_tools)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a11a1e-75f1-45ef-9070-3c5aff23a91d",
   "metadata": {},
   "source": [
    "#### Number of Irrelevant Items?\n",
    "\n",
    "Is precision going to be affected by the number of irrelevant items?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "39d7af30-2696-49b3-aaca-794046b77b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.15, 0.67)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_1 = [1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "result_2 = [1, 2, 3]\n",
    "\n",
    "relevant_chunks = [1, 2, 4, 10]\n",
    "\n",
    "# Which has a better recall?\n",
    "\n",
    "(\n",
    "    precision(result_1, relevant_chunks),\n",
    "    precision(result_2, relevant_chunks),\n",
    ")  # Precision is badly affected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6c670f-14f3-4388-b93a-e8c7e1731108",
   "metadata": {},
   "source": [
    "Therefore we can conclude that recall is **unaffected by the ordering of the items** and **unaffected by the number of irrelevant items**. It only cares about **the proportions of the relevant items that were retrieved**!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c4f3ab-acb2-4fb9-b797-7220dd64c887",
   "metadata": {},
   "source": [
    "## Precision vs Recall Tradeoff\n",
    "\n",
    "Choosing to optimize precision often comes at the cost of recall and vice versa. But how does this play out?\n",
    "\n",
    "| Recall | Precision | Interpretation                                                                 |\n",
    "| ------ | --------- | ------------------------------------------------------------------------------ |\n",
    "| High   | Low       | We have a shot if the LLM is robust to noise, might run out of context length. |\n",
    "| Low    | High      | We might give an incomplete answer, did not get all the content                |\n",
    "| High   | High      | If we do poorly here, it's because our generation prompt is...bad.             |\n",
    "| Low    | Low       | We're not doing well at all, nuke the system!                                  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "05a26a01-0eff-44e4-97fb-1c23ae906deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eg. I want super high recall\n",
    "\n",
    "result_1 = [\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    0,\n",
    "    2,\n",
    "]  # Hope our LLM is robust to noise and has enough context\n",
    "\n",
    "# Recall High, Precision Low\n",
    "\n",
    "# Eg. I want super high precision\n",
    "\n",
    "result_1 = [\n",
    "    1,\n",
    "    0,\n",
    "    0,\n",
    "]  # Missed out the 2 which was very far back ( Eg. incomplete answers )\n",
    "\n",
    "# Eg. I miraculously have high precision and recall\n",
    "\n",
    "result_1 = [1, 2]\n",
    "\n",
    "# Eg. Low\n",
    "\n",
    "result_1 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463c76a2-b2c6-4677-af12-9835be4f1be3",
   "metadata": {},
   "source": [
    "## Evaluating Our Data\n",
    "\n",
    "Let's see an example of how we can evaluate our data using the ms-marco dataset with real user queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d6900466-44ea-49e3-9a1a-9440e209a017",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "from lib.eval import calculate_reciprocal_rank, calculate_recall, score\n",
    "\n",
    "SIZES = [3, 5, 10, 15, 25]\n",
    "\n",
    "\n",
    "metrics = {\"mrr\": calculate_reciprocal_rank, \"recall\": calculate_recall}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "26543905-9a81-44cf-9c2a-1dd52610f3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 219/219 [00:04<00:00, 44.30it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mrr@3        0.347763\n",
       "mrr@5        0.395251\n",
       "mrr@10       0.423288\n",
       "mrr@15       0.425776\n",
       "mrr@25       0.426694\n",
       "recall@3     0.497717\n",
       "recall@5     0.707763\n",
       "recall@10    0.904110\n",
       "recall@15    0.936073\n",
       "recall@25    0.954338\n",
       "dtype: float64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "db = lancedb.connect(\"../lance\")\n",
    "table = db.open_table(\"ms_marco\")\n",
    "\n",
    "\n",
    "def load_jsonl_file(file_path):\n",
    "    data = []\n",
    "    with open(file_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            json_obj = json.loads(line.strip())\n",
    "            data.append(json_obj)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_k_relevant_chunk_ids(table, query, number):\n",
    "    return [\n",
    "        item[\"chunk_id\"]\n",
    "        for item in table.search(query, query_type=\"fts\").limit(number).to_list()\n",
    "    ]\n",
    "\n",
    "\n",
    "def score(preds, label: str | list[str]):\n",
    "    return {\n",
    "        f\"{fn_name}@{size}\": round(\n",
    "            metrics[fn_name](preds[:size], [label] if type(label) == str else label),\n",
    "            3,\n",
    "        )\n",
    "        for fn_name, size in product(metrics.keys(), SIZES)\n",
    "    }\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "data = load_jsonl_file(os.path.abspath(\"../data/queries_single_label.jsonl\"))\n",
    "\n",
    "scores = []\n",
    "for item in tqdm(data):\n",
    "    query = item[\"query\"]\n",
    "    selected_chunk = item[\"selected_chunk_id\"]\n",
    "    retrieved_chunk_ids = get_k_relevant_chunk_ids(table, query, max(SIZES))\n",
    "    scores.append(score(retrieved_chunk_ids, selected_chunk))\n",
    "\n",
    "df = pd.DataFrame(scores)\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2ad49af5-eb95-40e4-b055-acd048030143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 196/196 [00:04<00:00, 44.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mrr@3        0.380071\n",
       "mrr@5        0.424459\n",
       "mrr@10       0.450224\n",
       "mrr@15       0.452541\n",
       "mrr@25       0.453311\n",
       "recall@3     0.497449\n",
       "recall@5     0.703230\n",
       "recall@10    0.900510\n",
       "recall@15    0.933673\n",
       "recall@25    0.951531\n",
       "dtype: float64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "db = lancedb.connect(\"../lance\")\n",
    "table = db.open_table(\"ms_marco\")\n",
    "\n",
    "\n",
    "def load_jsonl_file(file_path):\n",
    "    data = []\n",
    "    with open(file_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            json_obj = json.loads(line.strip())\n",
    "            data.append(json_obj)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_k_relevant_chunk_ids(table, query, number):\n",
    "    return [\n",
    "        item[\"chunk_id\"]\n",
    "        for item in table.search(query, query_type=\"fts\").limit(number).to_list()\n",
    "    ]\n",
    "\n",
    "\n",
    "def score(preds, label: str | list[str]):\n",
    "    return {\n",
    "        f\"{fn_name}@{size}\": round(\n",
    "            metrics[fn_name](preds[:size], [label] if type(label) == str else label),\n",
    "            3,\n",
    "        )\n",
    "        for fn_name, size in product(metrics.keys(), SIZES)\n",
    "    }\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "data = load_jsonl_file(os.path.abspath(\"../data/queries_multi_label.jsonl\"))\n",
    "\n",
    "scores = []\n",
    "for item in tqdm(data):\n",
    "    query = item[\"query\"]\n",
    "    selected_chunk = item[\"selected_chunk_ids\"]\n",
    "    retrieved_chunk_ids = get_k_relevant_chunk_ids(table, query, max(SIZES))\n",
    "    scores.append(score(retrieved_chunk_ids, selected_chunk))\n",
    "\n",
    "df = pd.DataFrame(scores)\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4715a5-a1ed-4108-b1dc-18d5e1c59110",
   "metadata": {},
   "source": [
    "# Cold Starting\n",
    "\n",
    "What can we do if we have no user queries and we're just starting out? Well, the easiest way is to use synthethic queries to automatically generate the data to do so!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "47bffd5b-7e7a-4bae-8cb3-66a49baf587b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:02<00:00,  1.15it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'input': 'What is conversion disorder and how does it differ from factitious disorders and malingering?',\n",
       "  'source': 'Conversion disorder is a type of somatoform disorder where physical symptoms or signs are present that cannot be explained by a medical condition. Very importantly, unlike factitious disorders and malingering, the symptoms of somatoform disorders are not intentional or under conscious control of the patient'},\n",
       " {'input': 'What are the key features that differentiate conifers from other types of woody plants?',\n",
       "  'source': 'A conifer is a tree or shrub which produces distinctive cones as part of its sexual reproduction. These woody plants are classified among the gymnosperms, and they have a wide variety of uses, from trapping carbon in the environment to providing resins which can be used in the production of solvents. Several features beyond the cones set conifers apart from other types of woody plants. A conifer is typically evergreen, although some individuals are deciduous, and almost all conifers have needle or scale-like leaves'},\n",
       " {'input': 'What are some common names for Dascyllus aruanus?',\n",
       "  'source': 'Known by multiple common names, such as humbug damselfish, three-striped damselfish and white-tailed damselfish, Dascyllus aruanus is a feisty little fish that adapts well to aquarium life. Three-striped damselfish can be pugnacious and are better introduced at the latter stages of setting up a marine fish community. Remove as many of the three-striped damselfish fry as you want to try and raise to a rearing aquarium, with an absence of adult fish and invertebrates that might look upon the young fish as tasty morsels for the taking. Dascyllus aruanus is a worthy first-time breeding project for up-and-coming marine aquarists'}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import instructor\n",
    "import openai\n",
    "from pydantic import BaseModel, Field\n",
    "from tqdm.asyncio import tqdm_asyncio as asyncio\n",
    "\n",
    "client = instructor.from_openai(openai.AsyncOpenAI())\n",
    "\n",
    "\n",
    "class QuestionAnswerPair(BaseModel):\n",
    "    \"\"\"\n",
    "    This model represents a pair of a question generated from a text chunk, its corresponding answer,\n",
    "    and the chain of thought leading to the answer. The chain of thought provides insight into how the answer\n",
    "    was derived from the question.\n",
    "    \"\"\"\n",
    "\n",
    "    chain_of_thought: str = Field(\n",
    "        ..., description=\"The reasoning process leading to the answer.\"\n",
    "    )\n",
    "    question: str = Field(\n",
    "        ..., description=\"The generated question from the text chunk.\"\n",
    "    )\n",
    "    answer: str = Field(..., description=\"The answer to the generated question.\")\n",
    "\n",
    "\n",
    "async def generate_question_batch(text_chunk_batch):\n",
    "    async def generate_question(text: str):\n",
    "        question = await client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a world class AI that excels at generating hypothethical search queries. You're about to be given a text snippet and asked to generate a search query which is specific to the specific text chunk that you'll be given. Make sure to use information from the text chunk.\",\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": f\"Here is the text chunk : {text}\"},\n",
    "            ],\n",
    "            response_model=QuestionAnswerPair,\n",
    "            max_retries=3,\n",
    "        )\n",
    "        return (question, text)\n",
    "\n",
    "    coros = [generate_question(item) for item in text_chunk_batch]\n",
    "    res = await asyncio.gather(*coros)\n",
    "    return [{\"input\": item.question, \"source\": text} for item, text in res]\n",
    "\n",
    "\n",
    "chunks = [\n",
    "    \"Conversion disorder is a type of somatoform disorder where physical symptoms or signs are present that cannot be explained by a medical condition. Very importantly, unlike factitious disorders and malingering, the symptoms of somatoform disorders are not intentional or under conscious control of the patient\",\n",
    "    \"A conifer is a tree or shrub which produces distinctive cones as part of its sexual reproduction. These woody plants are classified among the gymnosperms, and they have a wide variety of uses, from trapping carbon in the environment to providing resins which can be used in the production of solvents. Several features beyond the cones set conifers apart from other types of woody plants. A conifer is typically evergreen, although some individuals are deciduous, and almost all conifers have needle or scale-like leaves\",\n",
    "    \"Known by multiple common names, such as humbug damselfish, three-striped damselfish and white-tailed damselfish, Dascyllus aruanus is a feisty little fish that adapts well to aquarium life. Three-striped damselfish can be pugnacious and are better introduced at the latter stages of setting up a marine fish community. Remove as many of the three-striped damselfish fry as you want to try and raise to a rearing aquarium, with an absence of adult fish and invertebrates that might look upon the young fish as tasty morsels for the taking. Dascyllus aruanus is a worthy first-time breeding project for up-and-coming marine aquarists\",\n",
    "]\n",
    "\n",
    "questions = await generate_question_batch(chunks)\n",
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a214a7-d41e-440d-9f27-ddbc388fe81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions[0][\"input\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9204c772-5eb4-4dc8-85a7-5fb3a615b13f",
   "metadata": {},
   "source": [
    "## Instructor\n",
    "\n",
    "Instructor is a library that provides structured output validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eab83b4-0435-4be4-b75f-3099e3007b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "# Define your desired output structure\n",
    "class UserInfo(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "\n",
    "\n",
    "# Patch the OpenAI client\n",
    "client = instructor.from_openai(OpenAI())\n",
    "\n",
    "# Extract structured data from natural language\n",
    "user_info = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    response_model=UserInfo,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"John Doe is 30 years old.\"}],\n",
    ")\n",
    "\n",
    "print(user_info.name)\n",
    "print(user_info.age)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ca0338-a836-4e92-83f4-530eb4140b36",
   "metadata": {},
   "source": [
    "### Exercises\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02f874f-a36f-433e-a552-71405b30fcf5",
   "metadata": {},
   "source": [
    "Now that we've seen what Instructor can do, let's work through a few different exercises to get a better understanding of the library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb96d96-d0d3-4130-8326-52db498e9b56",
   "metadata": {},
   "source": [
    "#### Adding some docstrings\n",
    "\n",
    "Let's try creating a Pydantic Model that has docstrings and descriptions using the `Field` object.\n",
    "\n",
    "Modify the original `UserInfo` object to include a docstring and a description of each field\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1860d4d9-0f24-4a9e-b0ef-ed4164756f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7f88c561-6963-487e-b037-67db291a8d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserInfo(BaseModel):\n",
    "    \"\"\"\n",
    "    This is a model which represents a single user's information\n",
    "    \"\"\"\n",
    "\n",
    "    name: str = Field(\n",
    "        ..., description=\"This is the user's name which we have extracted\"\n",
    "    )\n",
    "    age: int = Field(..., description=\"This is the user's age which we have extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8486342b-63bb-4cd3-8e60-96c743dba089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': \"This is a model which represents a single user's information\",\n",
       " 'properties': {'name': {'description': \"This is the user's name which we have extracted\",\n",
       "   'title': 'Name',\n",
       "   'type': 'string'},\n",
       "  'age': {'description': \"This is the user's age which we have extracted\",\n",
       "   'title': 'Age',\n",
       "   'type': 'integer'}},\n",
       " 'required': ['name', 'age'],\n",
       " 'title': 'UserInfo',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "UserInfo.model_json_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf7a843-efd4-459f-9719-302f0d81c4e0",
   "metadata": {},
   "source": [
    "#### Using simple validation\n",
    "\n",
    "Now that we've seen how to work with simple User Fields, let's start implementing validators.\n",
    "\n",
    "Validators are simple functions that run on the returned response from OpenAI. Using Validators, we can ensure that we have valid output. To show how a simple validator might work, let's try to implement a simple function which generates three categories given an article title.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0b1d33-e158-409b-9718-732fd35785f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import field_validator\n",
    "\n",
    "\n",
    "class Metadata(BaseModel):\n",
    "    \"\"\"\n",
    "    This is a model which represents a list of categories that we can classify the given article into\n",
    "    \"\"\"\n",
    "\n",
    "    categories: list[str] = Field(\n",
    "        ...,\n",
    "        description=\"This is the list of categories that we can classify the given article into\",\n",
    "    )\n",
    "    keywords: list[str] = Field(\n",
    "        ...,\n",
    "        description=\"These are some keywords that users might search for when looking for similar articles as the given article.\",\n",
    "    )\n",
    "\n",
    "    @field_validator(\"categories\")\n",
    "    def check_categories_length(cls, v):\n",
    "        if not (3 <= len(v) <= 5):\n",
    "            raise ValueError(\n",
    "                \"categories must have at least 3 elements and at most 5 elements\"\n",
    "            )\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2dd727-8eb5-4a9b-bc20-318334e07dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    response_model=Metadata,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a World Class classification Algorithm. You are about to be given an article title to classify. Make sure to return your response in the model provided\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Give me a sample article title for classification: The Future of Artificial Intelligence in Healthcare\",\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17113b2e-c9c4-443e-850a-4c4e30049abc",
   "metadata": {},
   "source": [
    "#### More Complex Types\n",
    "\n",
    "We've now seen how to use Pydantic to validate our returned types with instructor. Now let's try a more complex example\n",
    "\n",
    "Imagine you're trying to do some query parsing and you have a set of given tools\n",
    "\n",
    "1. Internet Search\n",
    "2. Database Queries\n",
    "3. Meeting Scheduler\n",
    "\n",
    "How might we represent this in a Pydantic Model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7b062968-e7ce-4653-8b34-93dd7eac875f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actions=[CalendarQuery(id=1, calendar='Personal', start_date='03-06', end_date='09-06', dependencies=[]), InternetSearch(id=2, search_query='best Japanese restaurants in Downtown Toronto', dependencies=[])]\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from typing import List, Literal, Union\n",
    "from pydantic import field_validator\n",
    "from openai import OpenAI\n",
    "import instructor\n",
    "\n",
    "client = instructor.from_openai(OpenAI())\n",
    "\n",
    "\n",
    "class InternetSearch(BaseModel):\n",
    "    \"\"\"\n",
    "    Model for representing an internet search query.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    id: int = Field(..., description=\"Unique id of the query\")\n",
    "    search_query: str = Field(\n",
    "        ...,\n",
    "        description=\"This is an internet search query that we will execute to identify relevant information.\",\n",
    "    )\n",
    "    dependencies: List[int] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"List of sub questions that need to be answered before asking this question\",\n",
    "    )\n",
    "\n",
    "\n",
    "class CalendarQuery(BaseModel):\n",
    "    \"\"\"\n",
    "    A model that represents\n",
    "    \"\"\"\n",
    "\n",
    "    id: int = Field(..., description=\"Unique id of the query\")\n",
    "    calendar: Literal[\"Personal\", \"Work\"] = Field(\n",
    "        ..., description=\"The type of calendar (Personal or Work).\"\n",
    "    )\n",
    "    start_date: str = Field(\n",
    "        ...,\n",
    "        description=\"The earliest date for events that we'd like to fetch for this calendar\",\n",
    "    )\n",
    "    end_date: str = Field(\n",
    "        ...,\n",
    "        description=\"The latest date for events that we'd like to fetch for this calendar\",\n",
    "    )\n",
    "    dependencies: List[int] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"List of sub questions that need to be answered before asking this question\",\n",
    "    )\n",
    "\n",
    "    @field_validator(\"start_date\", \"end_date\")\n",
    "    def validate_date_format(cls, value):\n",
    "        try:\n",
    "            datetime.strptime(value, \"%d-%m\")\n",
    "        except ValueError:\n",
    "            raise ValueError(\"Date must be in the format dd-mm\")\n",
    "        return value\n",
    "\n",
    "\n",
    "class QueryModel(BaseModel):\n",
    "    \"\"\"\n",
    "    A list of actions to execute in order to complete the user's request\n",
    "    \"\"\"\n",
    "\n",
    "    actions: List[Union[InternetSearch, CalendarQuery]] = Field(\n",
    "        ..., description=\"A list of actions.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def generate_actions(request: str) -> QueryModel:\n",
    "    \"\"\"\n",
    "    Generate a list of actions to schedule an appointment based on the user's request.\n",
    "    \"\"\"\n",
    "    return client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        response_model=QueryModel,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a scheduling assistant capable of breaking down complex user queries into actions to be executed. Do not answer the question but instead return a list of plausible steps in order to get enough information to answer the user's query\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"The date today is 27 May 2024, Monday. The user lives in Downtown Toronto and generally likes Japanese Food\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": request},\n",
    "        ],\n",
    "        max_retries=3,\n",
    "    )\n",
    "\n",
    "\n",
    "request = \"I'd like to grab dinner with Daniel sometime next week. Can you help me find some time in my calendar and some potential dinner spots?\"\n",
    "actions = generate_actions(request)\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e771aeb-2818-49f2-82cd-e16764cecc81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a862688d-b482-4698-bac0-8684c98f0753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c33c1d4-4081-4579-9a7a-a4209e3d9e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cc0694-928f-4cb7-8737-98397a281ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
