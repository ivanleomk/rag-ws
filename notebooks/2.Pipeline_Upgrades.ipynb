{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edcb553c-54f0-4f90-9dc8-a79c4fdbb2e9",
   "metadata": {},
   "source": [
    "# Upgrading our System\n",
    "\n",
    "In this notebook, we look at how we can use the previous building blocks that we put together to test different pipeline combinations. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ea3fcc-d12d-4f5d-8b2d-af26d559a2f7",
   "metadata": {},
   "source": [
    "In our previous notebook, we saw how we could evaluate a RAG system using some simple metrics such as recall. \n",
    "\n",
    "Let's see how we can use this to quickly experiment with different pipelines and get a quantiative idea of how good or bad different metrics stack up against each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9862ed5-0217-47bf-8a50-82733de8bc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [00:00<00:00, 14907.06it/s]\n",
      "100%|██████████| 219/219 [00:13<00:00, 16.79it/s]\n",
      "100%|██████████| 219/219 [00:06<00:00, 35.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+--------------------+\n",
      "|           |   Semantic Search |   Full Text Search |\n",
      "+===========+===================+====================+\n",
      "| mrr@3     |              0.44 |               0.35 |\n",
      "+-----------+-------------------+--------------------+\n",
      "| mrr@5     |              0.49 |               0.4  |\n",
      "+-----------+-------------------+--------------------+\n",
      "| mrr@10    |              0.51 |               0.42 |\n",
      "+-----------+-------------------+--------------------+\n",
      "| mrr@15    |              0.51 |               0.43 |\n",
      "+-----------+-------------------+--------------------+\n",
      "| mrr@25    |              0.51 |               0.43 |\n",
      "+-----------+-------------------+--------------------+\n",
      "| recall@3  |              0.64 |               0.5  |\n",
      "+-----------+-------------------+--------------------+\n",
      "| recall@5  |              0.86 |               0.71 |\n",
      "+-----------+-------------------+--------------------+\n",
      "| recall@10 |              0.99 |               0.9  |\n",
      "+-----------+-------------------+--------------------+\n",
      "| recall@15 |              1    |               0.94 |\n",
      "+-----------+-------------------+--------------------+\n",
      "| recall@25 |              1    |               0.95 |\n",
      "+-----------+-------------------+--------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from lib.data import get_labels\n",
    "from lib.query import full_text_search, semantic_search\n",
    "from lib.eval import score\n",
    "from lib.models import EmbeddedPassage\n",
    "from lib.db import get_table\n",
    "import pandas as pd\n",
    "import lancedb\n",
    "from tabulate import tabulate\n",
    "\n",
    "db = lancedb.connect(\"../lance\")\n",
    "\n",
    "candidates = {\"Semantic Search\": semantic_search, \"Full Text Search\": full_text_search}\n",
    "\n",
    "test_data = get_labels(\"../data/queries_single_label.jsonl\")\n",
    "table = get_table(db, \"ms_marco\", EmbeddedPassage)\n",
    "\n",
    "# Run test_data against candidates\n",
    "results = {}\n",
    "\n",
    "for candidate, search_fn in candidates.items():\n",
    "    search_results = search_fn(table, test_data, 25)\n",
    "    evaluation_metrics = [\n",
    "        score(retrieved_chunk_ids, query[\"selected_chunk_id\"])\n",
    "        for retrieved_chunk_ids, query in zip(search_results, test_data)\n",
    "    ]\n",
    "    results[candidate] = pd.DataFrame(evaluation_metrics).mean()\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Print the table\n",
    "print(tabulate(df.round(2), headers=\"keys\", tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979dd59b-3373-4c81-8cc2-0c9620679ce9",
   "metadata": {},
   "source": [
    "We can immediately notice a few different things for our system\n",
    "\n",
    "- We can match `recall@5` for Semantic Search using say a larger value of `k` for Full Text Search. The `recall@10` for full text search is 0.9 while the `recall@5` for Semantic search is 0.86\n",
    "- Our MRR isn't the best for Full Text Search and we never quite match up to the performance of full text search.\n",
    "\n",
    "What other options do we have?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441898af-39f7-4e7a-9ebd-979aacb7c755",
   "metadata": {},
   "source": [
    "# Our Evaluation Dataset\n",
    "\n",
    "What exactly have we been benchmarking our results with and what's included within the MsMarco Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1b19d6fd-0840-4847-ac8d-f1f5d40b8fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IterableDataset({\n",
       "    features: ['answers', 'passages', 'query', 'query_id', 'query_type', 'wellFormedAnswers'],\n",
       "    n_shards: 1\n",
       "})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"ms_marco\", \"v1.1\", split=\"train\", streaming=True).take(4)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0451c401-7fb7-44a6-8a34-e4a0f682e677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answers': ['Results-Based Accountability is a disciplined way of thinking and taking action that communities can use to improve the lives of children, youth, families, adults and the community as a whole.'],\n",
       " 'passages': {'is_selected': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "  'passage_text': [\"Since 2007, the RBA's outstanding reputation has been affected by the 'Securency' or NPA scandal. These RBA subsidiaries were involved in bribing overseas officials so that Australia might win lucrative note-printing contracts. The assets of the bank include the gold and foreign exchange reserves of Australia, which is estimated to have a net worth of A$101 billion. Nearly 94% of the RBA's employees work at its headquarters in Sydney, New South Wales and at the Business Resumption Site.\",\n",
       "   \"The Reserve Bank of Australia (RBA) came into being on 14 January 1960 as Australia 's central bank and banknote issuing authority, when the Reserve Bank Act 1959 removed the central banking functions from the Commonwealth Bank. The assets of the bank include the gold and foreign exchange reserves of Australia, which is estimated to have a net worth of A$101 billion. Nearly 94% of the RBA's employees work at its headquarters in Sydney, New South Wales and at the Business Resumption Site.\",\n",
       "   'RBA Recognized with the 2014 Microsoft US Regional Partner of the ... by PR Newswire. Contract Awarded for supply and support the. Securitisations System used for risk management and analysis. ',\n",
       "   'The inner workings of a rebuildable atomizer are surprisingly simple. The coil inside the RBA is made of some type of resistance wire, normally Kanthal or nichrome. When a current is applied to the coil (resistance wire), it heats up and the heated coil then vaporizes the eliquid. 1 The bottom feed RBA is, perhaps, the easiest of all RBA types to build, maintain, and use. 2  It is filled from below, much like bottom coil clearomizer. 3  Bottom feed RBAs can utilize cotton instead of silica for the wick. 4  The Genesis, or genny, is a top feed RBA that utilizes a short woven mesh wire.',\n",
       "   'Results-Based Accountability® (also known as RBA) is a disciplined way of thinking and taking action that communities can use to improve the lives of children, youth, families, adults and the community as a whole. RBA is also used by organizations to improve the performance of their programs. RBA improves the lives of children, families, and communities and the performance of programs because RBA: 1  Gets from talk to action quickly; 2  Is a simple, common sense process that everyone can understand; 3  Helps groups to surface and challenge assumptions that can be barriers to innovation;',\n",
       "   'Results-Based Accountability® (also known as RBA) is a disciplined way of thinking and taking action that communities can use to improve the lives of children, youth, families, adults and the community as a whole. RBA is also used by organizations to improve the performance of their programs. Creating Community Impact with RBA. Community impact focuses on conditions of well-being for children, families and the community as a whole that a group of leaders is working collectively to improve. For example: “Residents with good jobs,” “Children ready for school,” or “A safe and clean neighborhood”.',\n",
       "   'RBA uses a data-driven, decision-making process to help communities and organizations get beyond talking about problems to taking action to solve problems. It is a simple, common sense framework that everyone can understand. RBA starts with ends and works backward, towards means. The “end” or difference you are trying to make looks slightly different if you are working on a broad community level or are focusing on your specific program or organization. RBA improves the lives of children, families, and communities and the performance of programs because RBA: 1  Gets from talk to action quickly; 2  Is a simple, common sense process that everyone can understand; 3  Helps groups to surface and challenge assumptions that can be barriers to innovation;',\n",
       "   'vs. NetIQ Identity Manager. Risk-based authentication (RBA) is a method of applying varying levels of stringency to authentication processes based on the likelihood that access to a given system could result in its being compromised. Risk-based authentication can be categorized as either user-dependent or transaction-dependent. User-dependent RBA processes employ the same authentication for every session initiated by a given user; the exact credentials that the site demands depend on who the user is.',\n",
       "   'A rebuildable atomizer (RBA), often referred to as simply a “rebuildable,” is just a special type of atomizer used in the Vape Pen and Mod Industry that connects to a personal vaporizer. 1 The bottom feed RBA is, perhaps, the easiest of all RBA types to build, maintain, and use. 2  It is filled from below, much like bottom coil clearomizer. 3  Bottom feed RBAs can utilize cotton instead of silica for the wick. 4  The Genesis, or genny, is a top feed RBA that utilizes a short woven mesh wire.',\n",
       "   'Get To Know Us. RBA is a digital and technology consultancy with roots in strategy, design and technology. Our team of specialists help progressive companies deliver modern digital experiences backed by proven technology engineering. '],\n",
       "  'url': ['https://en.wikipedia.org/wiki/Reserve_Bank_of_Australia',\n",
       "   'https://en.wikipedia.org/wiki/Reserve_Bank_of_Australia',\n",
       "   'http://acronyms.thefreedictionary.com/RBA',\n",
       "   'https://www.slimvapepen.com/rebuildable-atomizer-rba/',\n",
       "   'http://rba-africa.com/about/what-is-rba/',\n",
       "   'http://resultsleadership.org/what-is-results-based-accountability-rba/',\n",
       "   'http://rba-africa.com/about/what-is-rba/',\n",
       "   'http://searchsecurity.techtarget.com/definition/risk-based-authentication-RBA',\n",
       "   'https://www.slimvapepen.com/rebuildable-atomizer-rba/',\n",
       "   'http://www.rbaconsulting.com/']},\n",
       " 'query': 'what is rba',\n",
       " 'query_id': 19699,\n",
       " 'query_type': 'description',\n",
       " 'wellFormedAnswers': []}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item = next(iter(dataset))\n",
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "93f84c3f-24de-43da-92ac-a65882fb881f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'is_selected': [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       " 'passage_text': [\"Since 2007, the RBA's outstanding reputation has been affected by the 'Securency' or NPA scandal. These RBA subsidiaries were involved in bribing overseas officials so that Australia might win lucrative note-printing contracts. The assets of the bank include the gold and foreign exchange reserves of Australia, which is estimated to have a net worth of A$101 billion. Nearly 94% of the RBA's employees work at its headquarters in Sydney, New South Wales and at the Business Resumption Site.\",\n",
       "  \"The Reserve Bank of Australia (RBA) came into being on 14 January 1960 as Australia 's central bank and banknote issuing authority, when the Reserve Bank Act 1959 removed the central banking functions from the Commonwealth Bank. The assets of the bank include the gold and foreign exchange reserves of Australia, which is estimated to have a net worth of A$101 billion. Nearly 94% of the RBA's employees work at its headquarters in Sydney, New South Wales and at the Business Resumption Site.\",\n",
       "  'RBA Recognized with the 2014 Microsoft US Regional Partner of the ... by PR Newswire. Contract Awarded for supply and support the. Securitisations System used for risk management and analysis. ',\n",
       "  'The inner workings of a rebuildable atomizer are surprisingly simple. The coil inside the RBA is made of some type of resistance wire, normally Kanthal or nichrome. When a current is applied to the coil (resistance wire), it heats up and the heated coil then vaporizes the eliquid. 1 The bottom feed RBA is, perhaps, the easiest of all RBA types to build, maintain, and use. 2  It is filled from below, much like bottom coil clearomizer. 3  Bottom feed RBAs can utilize cotton instead of silica for the wick. 4  The Genesis, or genny, is a top feed RBA that utilizes a short woven mesh wire.',\n",
       "  'Results-Based Accountability® (also known as RBA) is a disciplined way of thinking and taking action that communities can use to improve the lives of children, youth, families, adults and the community as a whole. RBA is also used by organizations to improve the performance of their programs. RBA improves the lives of children, families, and communities and the performance of programs because RBA: 1  Gets from talk to action quickly; 2  Is a simple, common sense process that everyone can understand; 3  Helps groups to surface and challenge assumptions that can be barriers to innovation;',\n",
       "  'Results-Based Accountability® (also known as RBA) is a disciplined way of thinking and taking action that communities can use to improve the lives of children, youth, families, adults and the community as a whole. RBA is also used by organizations to improve the performance of their programs. Creating Community Impact with RBA. Community impact focuses on conditions of well-being for children, families and the community as a whole that a group of leaders is working collectively to improve. For example: “Residents with good jobs,” “Children ready for school,” or “A safe and clean neighborhood”.',\n",
       "  'RBA uses a data-driven, decision-making process to help communities and organizations get beyond talking about problems to taking action to solve problems. It is a simple, common sense framework that everyone can understand. RBA starts with ends and works backward, towards means. The “end” or difference you are trying to make looks slightly different if you are working on a broad community level or are focusing on your specific program or organization. RBA improves the lives of children, families, and communities and the performance of programs because RBA: 1  Gets from talk to action quickly; 2  Is a simple, common sense process that everyone can understand; 3  Helps groups to surface and challenge assumptions that can be barriers to innovation;',\n",
       "  'vs. NetIQ Identity Manager. Risk-based authentication (RBA) is a method of applying varying levels of stringency to authentication processes based on the likelihood that access to a given system could result in its being compromised. Risk-based authentication can be categorized as either user-dependent or transaction-dependent. User-dependent RBA processes employ the same authentication for every session initiated by a given user; the exact credentials that the site demands depend on who the user is.',\n",
       "  'A rebuildable atomizer (RBA), often referred to as simply a “rebuildable,” is just a special type of atomizer used in the Vape Pen and Mod Industry that connects to a personal vaporizer. 1 The bottom feed RBA is, perhaps, the easiest of all RBA types to build, maintain, and use. 2  It is filled from below, much like bottom coil clearomizer. 3  Bottom feed RBAs can utilize cotton instead of silica for the wick. 4  The Genesis, or genny, is a top feed RBA that utilizes a short woven mesh wire.',\n",
       "  'Get To Know Us. RBA is a digital and technology consultancy with roots in strategy, design and technology. Our team of specialists help progressive companies deliver modern digital experiences backed by proven technology engineering. '],\n",
       " 'url': ['https://en.wikipedia.org/wiki/Reserve_Bank_of_Australia',\n",
       "  'https://en.wikipedia.org/wiki/Reserve_Bank_of_Australia',\n",
       "  'http://acronyms.thefreedictionary.com/RBA',\n",
       "  'https://www.slimvapepen.com/rebuildable-atomizer-rba/',\n",
       "  'http://rba-africa.com/about/what-is-rba/',\n",
       "  'http://resultsleadership.org/what-is-results-based-accountability-rba/',\n",
       "  'http://rba-africa.com/about/what-is-rba/',\n",
       "  'http://searchsecurity.techtarget.com/definition/risk-based-authentication-RBA',\n",
       "  'https://www.slimvapepen.com/rebuildable-atomizer-rba/',\n",
       "  'http://www.rbaconsulting.com/']}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item[\"passages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b01a1e4-dabb-450d-9416-4ba0c0daf792",
   "metadata": {},
   "source": [
    "The MS-Marco dataset is a dataset that benchmarks the ability of models to do information retrieval. \n",
    "\n",
    "Each item in the dataset consists of a few different bits of information\n",
    "\n",
    "- `query` : This is the query that the original user made on Bing\n",
    "- `passages` \n",
    "  - `is_selected` : This is a binary label that indicates whether a human annotator found this query relevant when composing a response to the query. A 1 indicates that it's relevant and 0 indicates that it's not. **Note that multiple passages can be selected as relevant**\n",
    "  - `passage_test` : This is a list of passages that was returned which corresponds to the `is_selected` index\n",
    "\n",
    "We then compute a unique chunk_id for each passage using the `hashlib` library with the `md5` hash. This then allows us to use each item and its corresponding hash to generate two small test files in `.jsonl` format.\n",
    "\n",
    "- `queries_multi_label` : This contains a mapping of query to one or more selected passages\n",
    "\n",
    "    ```\n",
    "    {\"query\": \"in animals somatic cells are produced by and gametic cells are produced by\", \"selected_chunk_ids\":  [\"4ff0ed20afce65c76bdb0df809ef5025\", \"0f556defd6442767c1fee0e729f942fb\"]}\n",
    "    ```\n",
    "  \n",
    "- `queries_single_label`: This contains a mapping of a query to a single selected passage\n",
    "\n",
    "    ```\n",
    "    {\"query\": \"how much time can you go between oil changes\", \"selected_chunk_id\": \"c944888dc7bb30a1a01cf5c19776a19b\"}\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f17733f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('5eb63bbbe01eeed093cb22bb8f5acdc3', '68df723b3e61541ec5af9c6053357942')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "\n",
    "def compute_md5_hash(input_string: str) -> str:\n",
    "    \"\"\"\n",
    "    Compute the MD5 hash of a given string.\n",
    "\n",
    "    Parameters:\n",
    "    input_string (str): The input string to hash.\n",
    "\n",
    "    Returns:\n",
    "    str: The MD5 hash of the input string.\n",
    "    \"\"\"\n",
    "    md5_hash = hashlib.md5(input_string.encode())\n",
    "    return md5_hash.hexdigest()\n",
    "\n",
    "\n",
    "compute_md5_hash(\"hello world\"), compute_md5_hash(\"HEllo world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ee5dff-b0d3-4e58-afbc-4747af22a78b",
   "metadata": {},
   "source": [
    "## Hybrid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b876555f-2b0c-4dac-b2fc-8b18d9926e4a",
   "metadata": {},
   "source": [
    "If we look at the `query_type` for LanceDB, we'll notice that there's an additional query_type called `hybrid`. What's this new query type and how does it perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4495b046-9248-4daa-a7f8-6f407b88e0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 40865.67it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 219/219 [00:09<00:00, 23.42it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 219/219 [00:05<00:00, 37.06it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████| 219/219 [02:01<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+--------------------+-----------------+\n",
      "|           |   Semantic Search |   Full Text Search |   Hybrid Search |\n",
      "+===========+===================+====================+=================+\n",
      "| mrr@3     |              0.44 |               0.35 |            0.37 |\n",
      "+-----------+-------------------+--------------------+-----------------+\n",
      "| mrr@5     |              0.49 |               0.4  |            0.42 |\n",
      "+-----------+-------------------+--------------------+-----------------+\n",
      "| mrr@10    |              0.51 |               0.42 |            0.45 |\n",
      "+-----------+-------------------+--------------------+-----------------+\n",
      "| mrr@15    |              0.51 |               0.43 |            0.45 |\n",
      "+-----------+-------------------+--------------------+-----------------+\n",
      "| mrr@25    |              0.51 |               0.43 |            0.45 |\n",
      "+-----------+-------------------+--------------------+-----------------+\n",
      "| recall@3  |              0.64 |               0.5  |            0.55 |\n",
      "+-----------+-------------------+--------------------+-----------------+\n",
      "| recall@5  |              0.86 |               0.71 |            0.75 |\n",
      "+-----------+-------------------+--------------------+-----------------+\n",
      "| recall@10 |              0.99 |               0.9  |            0.95 |\n",
      "+-----------+-------------------+--------------------+-----------------+\n",
      "| recall@15 |              1    |               0.94 |            0.99 |\n",
      "+-----------+-------------------+--------------------+-----------------+\n",
      "| recall@25 |              1    |               0.95 |            1    |\n",
      "+-----------+-------------------+--------------------+-----------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from lib.data import get_labels\n",
    "from lib.query import full_text_search, semantic_search, hybrid_search\n",
    "from lib.eval import score\n",
    "from lib.models import EmbeddedPassage\n",
    "from lib.db import get_table\n",
    "import pandas as pd\n",
    "import lancedb\n",
    "from tabulate import tabulate\n",
    "\n",
    "db = lancedb.connect(\"../lance\")\n",
    "\n",
    "candidates = {\n",
    "    \"Semantic Search\": semantic_search,\n",
    "    \"Full Text Search\": full_text_search,\n",
    "    \"Hybrid Search\": hybrid_search,\n",
    "}\n",
    "\n",
    "test_data = get_labels(\"../data/queries_single_label.jsonl\")\n",
    "table = get_table(db, \"ms_marco\", EmbeddedPassage)\n",
    "\n",
    "# Run test_data against candidates\n",
    "results = {}\n",
    "\n",
    "for candidate, search_fn in candidates.items():\n",
    "    search_results = search_fn(table, test_data, 25)\n",
    "    evaluation_metrics = [\n",
    "        score(retrieved_chunk_ids, query[\"selected_chunk_id\"])\n",
    "        for retrieved_chunk_ids, query in zip(search_results, test_data)\n",
    "    ]\n",
    "    results[candidate] = pd.DataFrame(evaluation_metrics).mean()\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Print the table\n",
    "print(tabulate(df.round(2), headers=\"keys\", tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53515bed-31c0-4dd9-93dd-cad568952d8c",
   "metadata": {},
   "source": [
    "But what's happening under the hood? Why are our new results in between Semantic Search and Full Text Search?\n",
    "\n",
    "Turns out LanceDB is actually using a linear_combination_search reranker under the hood, combining the value of semantic search + full text search distance metrics with a weight of 0.7 for semantic search and 0.3 for full text search by default. [Link to Documentation](https://lancedb.github.io/lancedb/hybrid_search/hybrid_search/#arguments)\n",
    "\n",
    "Can we tune this weight hyper-parameter and get better results using this naive linear combination reranker?\n",
    "\n",
    "```python\n",
    "from lancedb.rerankers import LinearCombinationReranker\n",
    "\n",
    "reranker = LinearCombinationReranker(weight=0.3) # Use 0.3 as the weight for vector search\n",
    "\n",
    "# We can pass in a linear reranker here to do the re-ranking\n",
    "results = table.search(\"rebel\", query_type=\"hybrid\").rerank(reranker=reranker).to_pandas()\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a0533a3-d932-4fe4-93d7-0a0650e94f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Linear Combination (Weight 0.3): 100%|██████████████████████████████████████████████████████████| 20/20 [00:10<00:00,  1.97it/s]\n",
      "Linear Combination (Weight 0.7): 100%|██████████████████████████████████████████████████████████| 20/20 [00:10<00:00,  1.99it/s]\n",
      "Linear Combination (Weight 0.9): 100%|██████████████████████████████████████████████████████████| 20/20 [00:10<00:00,  1.84it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 3663.15it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 33.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------------------+----------------------------+----------------------------+-------------------+\n",
      "|           |   Linear Combination (0.3) |   Linear Combination (0.7) |   Linear Combination (0.9) |   Semantic Search |\n",
      "+===========+============================+============================+============================+===================+\n",
      "| mrr@3     |                       0.31 |                       0.35 |                       0.35 |              0.4  |\n",
      "+-----------+----------------------------+----------------------------+----------------------------+-------------------+\n",
      "| mrr@5     |                       0.37 |                       0.4  |                       0.4  |              0.45 |\n",
      "+-----------+----------------------------+----------------------------+----------------------------+-------------------+\n",
      "| mrr@10    |                       0.4  |                       0.43 |                       0.43 |              0.45 |\n",
      "+-----------+----------------------------+----------------------------+----------------------------+-------------------+\n",
      "| mrr@15    |                       0.4  |                       0.43 |                       0.43 |              0.45 |\n",
      "+-----------+----------------------------+----------------------------+----------------------------+-------------------+\n",
      "| mrr@25    |                       0.4  |                       0.43 |                       0.43 |              0.45 |\n",
      "+-----------+----------------------------+----------------------------+----------------------------+-------------------+\n",
      "| recall@3  |                       0.55 |                       0.6  |                       0.6  |              0.75 |\n",
      "+-----------+----------------------------+----------------------------+----------------------------+-------------------+\n",
      "| recall@5  |                       0.8  |                       0.8  |                       0.8  |              1    |\n",
      "+-----------+----------------------------+----------------------------+----------------------------+-------------------+\n",
      "| recall@10 |                       1    |                       1    |                       1    |              1    |\n",
      "+-----------+----------------------------+----------------------------+----------------------------+-------------------+\n",
      "| recall@15 |                       1    |                       1    |                       1    |              1    |\n",
      "+-----------+----------------------------+----------------------------+----------------------------+-------------------+\n",
      "| recall@25 |                       1    |                       1    |                       1    |              1    |\n",
      "+-----------+----------------------------+----------------------------+----------------------------+-------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from lib.query import linear_combination_search, semantic_search\n",
    "from lib.data import get_labels\n",
    "from lib.eval import score\n",
    "from lib.models import EmbeddedPassage\n",
    "from lib.db import get_table\n",
    "import pandas as pd\n",
    "import lancedb\n",
    "from tabulate import tabulate\n",
    "\n",
    "db = lancedb.connect(\"../lance\")\n",
    "\n",
    "weightage = [0.3, 0.7, 0.9]\n",
    "\n",
    "test_data = get_labels(\"../data/queries_single_label.jsonl\")[:20]\n",
    "table = get_table(db, \"ms_marco\", EmbeddedPassage)\n",
    "\n",
    "# Run test_data against candidates\n",
    "results = {}\n",
    "\n",
    "for weight in weightage:\n",
    "    search_results = linear_combination_search(table, test_data, 25, weight)\n",
    "    evaluation_metrics = [\n",
    "        score(retrieved_chunk_ids, query[\"selected_chunk_id\"])\n",
    "        for retrieved_chunk_ids, query in zip(search_results, test_data)\n",
    "    ]\n",
    "    results[f\"Linear Combination ({weight})\"] = pd.DataFrame(evaluation_metrics).mean()\n",
    "\n",
    "# Do Semantic Search\n",
    "search_results = semantic_search(table, test_data, 25)\n",
    "evaluation_metrics = [\n",
    "    score(retrieved_chunk_ids, query[\"selected_chunk_id\"])\n",
    "    for retrieved_chunk_ids, query in zip(search_results, test_data)\n",
    "]\n",
    "results[\"Semantic Search\"] = pd.DataFrame(evaluation_metrics).mean()\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Print the table\n",
    "print(tabulate(df.round(2), headers=\"keys\", tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765a1f95-3de6-408f-970a-dd636c75c551",
   "metadata": {},
   "source": [
    "# Re-Rankers\n",
    "\n",
    "Re-Rankers will often be much more accurate at finding relevant documents as compared to simple embedding search because they're able to extract out significantly more information from the query (and the text itself)\n",
    "\n",
    "Typically we'd utilise a re-ranker in a two step re-ranking process\n",
    "\n",
    "1. First fetch the relevant chunks\n",
    "2. Throw into a re-ranker\n",
    "3. Then return a subset of the re-ranked elements\n",
    "\n",
    "This will allow us to take advantage of the fast retrieval of embedding search to quickly narrow down the subset of evaluated chunks while combining the increased accuracy of a re-ranker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d5b39f-ef0c-4dcc-b252-60b90444dfea",
   "metadata": {},
   "source": [
    "## Cohere Re-Ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f1ca917-5ad9-4983-85e2-a00428e8a40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.query import linear_combination_search, semantic_search\n",
    "from lib.data import get_labels\n",
    "from lib.models import EmbeddedPassage\n",
    "from lib.db import get_table\n",
    "import lancedb\n",
    "\n",
    "\n",
    "db = lancedb.connect(\"../lance\")\n",
    "\n",
    "weightage = [0.3, 0.7, 0.9]\n",
    "\n",
    "test_data = get_labels(\"../data/queries_single_label.jsonl\")[:20]\n",
    "table = get_table(db, \"ms_marco\", EmbeddedPassage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffd0d9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'what is rba',\n",
       " 'selected_chunk_id': 'ca869ae1ed3f5021cb5b2a0b78cc846c'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85be5c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mrr@3': 0,\n",
       " 'mrr@5': 0,\n",
       " 'mrr@10': 0.167,\n",
       " 'mrr@15': 0.167,\n",
       " 'mrr@25': 0.167,\n",
       " 'recall@3': 0.0,\n",
       " 'recall@5': 0.0,\n",
       " 'recall@10': 1.0,\n",
       " 'recall@15': 1.0,\n",
       " 'recall@25': 1.0}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normal_search(query, table, limit):\n",
    "    return [\n",
    "        item[\"chunk_id\"]\n",
    "        for item in table.search(query, query_type=\"fts\")\n",
    "        .limit(limit)\n",
    "        .to_list()\n",
    "    ]\n",
    "\n",
    "\n",
    "query = test_data[0]\n",
    "retrieved_chunk_ids = normal_search(query[\"query\"], table, 25)\n",
    "evaluation_metrics = score(retrieved_chunk_ids, query[\"selected_chunk_id\"])\n",
    "evaluation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1dd4dcf-fa80-41c6-aed0-f2b463c9578e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mrr@3': 1.0,\n",
       " 'mrr@5': 1.0,\n",
       " 'mrr@10': 1.0,\n",
       " 'mrr@15': 1.0,\n",
       " 'mrr@25': 1.0,\n",
       " 'recall@3': 1.0,\n",
       " 'recall@5': 1.0,\n",
       " 'recall@10': 1.0,\n",
       " 'recall@15': 1.0,\n",
       " 'recall@25': 1.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lancedb.rerankers import CohereReranker\n",
    "\n",
    "\n",
    "def rerank_search(query, table, limit):\n",
    "    reranker = CohereReranker(\n",
    "        model_name=\"rerank-english-v2.0\"\n",
    "    )  # This uses the rerank-english\n",
    "    return [\n",
    "        item[\"chunk_id\"]\n",
    "        for item in table.search(query, query_type=\"fts\")\n",
    "        .limit(limit)\n",
    "        .rerank(reranker=reranker)\n",
    "        .to_list()\n",
    "    ]\n",
    "\n",
    "\n",
    "query = test_data[0]\n",
    "retrieved_chunk_ids = rerank_search(query[\"query\"], table, 25)\n",
    "evaluation_metrics = score(retrieved_chunk_ids, query[\"selected_chunk_id\"])\n",
    "evaluation_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b2d1ee1-4278-4072-9e4e-813b5576bb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:10<00:00,  1.89it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mrr@3        0.5833\n",
       "mrr@5        0.6058\n",
       "mrr@10       0.6058\n",
       "mrr@15       0.6058\n",
       "mrr@25       0.6058\n",
       "recall@3     0.8000\n",
       "recall@5     0.9000\n",
       "recall@10    0.9000\n",
       "recall@15    0.9000\n",
       "recall@25    0.9000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "scores = []\n",
    "for query in tqdm(test_data):\n",
    "    retrieved_chunk_ids = rerank_search(query[\"query\"], table, 25)\n",
    "    evaluation_metrics = score(retrieved_chunk_ids, query[\"selected_chunk_id\"])\n",
    "    scores.append(evaluation_metrics)\n",
    "\n",
    "df = pd.DataFrame(scores)\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f4373f9-cc26-4e3d-849e-336c26abb034",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 196/196 [02:28<00:00,  1.32it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mrr@3        0.522066\n",
       "mrr@5        0.565179\n",
       "mrr@10       0.575582\n",
       "mrr@15       0.575582\n",
       "mrr@25       0.575898\n",
       "recall@3     0.714286\n",
       "recall@5     0.897959\n",
       "recall@10    0.964286\n",
       "recall@15    0.964286\n",
       "recall@25    0.969388\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = []\n",
    "for query in tqdm(test_queries):\n",
    "    retrieved_chunk_ids = rerank_search(\n",
    "        query[\"query\"], table, 50\n",
    "    )  # What if we increase the #\n",
    "    evaluation_metrics = score(retrieved_chunk_ids, query[\"selected_chunk_id\"])\n",
    "    scores.append(evaluation_metrics)\n",
    "\n",
    "df = pd.DataFrame(scores)\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3ba3b8-ce01-4397-98af-73b86459d9ed",
   "metadata": {},
   "source": [
    "### Sample Evaluation : Which Model to use?\n",
    "\n",
    "Cohere ships a few different re-ranker models ( `rerank-english-v3.0`, `rerank-multilingual-v3.0`, `rerank-english-v2.0`, `rerank-multilingual-v2.0`) that perform slightly differently based on the use-case. How can we determine what might work best for our use case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f2b4467-b890-4c9c-b2ee-0c4b38ee4cea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 2262.30it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 32.17it/s]\n",
      "Cohere Reranker (rerank-english-v3.0): 100%|██████████████████████████████████████████████████████| 5/5 [00:04<00:00,  1.20it/s]\n",
      "Cohere Reranker (rerank-multilingual-v3.0): 100%|█████████████████████████████████████████████████| 5/5 [00:04<00:00,  1.15it/s]\n",
      "Cohere Reranker (rerank-english-v2.0): 100%|██████████████████████████████████████████████████████| 5/5 [00:04<00:00,  1.05it/s]\n",
      "Cohere Reranker (rerank-multilingual-v2.0): 100%|█████████████████████████████████████████████████| 5/5 [00:04<00:00,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------------+--------------+--------------+--------------+--------------+\n",
      "|           |   Semantic Search |   (rr-eng-3) |   (rr-mul-3) |   (rr-eng-2) |   (rr-mul-2) |\n",
      "+===========+===================+==============+==============+==============+==============+\n",
      "| mrr@3     |              0.47 |         0.4  |         0.77 |         0.6  |         0.53 |\n",
      "+-----------+-------------------+--------------+--------------+--------------+--------------+\n",
      "| mrr@5     |              0.47 |         0.49 |         0.77 |         0.64 |         0.53 |\n",
      "+-----------+-------------------+--------------+--------------+--------------+--------------+\n",
      "| mrr@10    |              0.47 |         0.52 |         0.77 |         0.67 |         0.53 |\n",
      "+-----------+-------------------+--------------+--------------+--------------+--------------+\n",
      "| mrr@15    |              0.47 |         0.52 |         0.77 |         0.67 |         0.53 |\n",
      "+-----------+-------------------+--------------+--------------+--------------+--------------+\n",
      "| mrr@25    |              0.47 |         0.52 |         0.77 |         0.67 |         0.53 |\n",
      "+-----------+-------------------+--------------+--------------+--------------+--------------+\n",
      "| recall@3  |              1    |         0.4  |         1    |         0.6  |         1    |\n",
      "+-----------+-------------------+--------------+--------------+--------------+--------------+\n",
      "| recall@5  |              1    |         0.8  |         1    |         0.8  |         1    |\n",
      "+-----------+-------------------+--------------+--------------+--------------+--------------+\n",
      "| recall@10 |              1    |         1    |         1    |         1    |         1    |\n",
      "+-----------+-------------------+--------------+--------------+--------------+--------------+\n",
      "| recall@15 |              1    |         1    |         1    |         1    |         1    |\n",
      "+-----------+-------------------+--------------+--------------+--------------+--------------+\n",
      "| recall@25 |              1    |         1    |         1    |         1    |         1    |\n",
      "+-----------+-------------------+--------------+--------------+--------------+--------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from lib.query import cohere_rerank_search, semantic_search\n",
    "from lib.data import get_labels\n",
    "from lib.eval import score\n",
    "from lib.models import EmbeddedPassage\n",
    "from lib.db import get_table\n",
    "import pandas as pd\n",
    "import lancedb\n",
    "from tabulate import tabulate\n",
    "\n",
    "db = lancedb.connect(\"../lance\")\n",
    "model_names = {\n",
    "    \"rr-eng-3\": \"rerank-english-v3.0\",\n",
    "    \"rr-mul-3\": \"rerank-multilingual-v3.0\",\n",
    "    \"rr-eng-2\": \"rerank-english-v2.0\",\n",
    "    \"rr-mul-2\": \"rerank-multilingual-v2.0\",\n",
    "}\n",
    "\n",
    "test_data = get_labels(\"../data/queries_single_label.jsonl\")[:5]\n",
    "table = get_table(db, \"ms_marco\", EmbeddedPassage)\n",
    "\n",
    "# Run test_data against candidates\n",
    "results = {}\n",
    "\n",
    "# Do Semantic Search\n",
    "search_results = semantic_search(table, test_data, 25)\n",
    "evaluation_metrics = [\n",
    "    score(retrieved_chunk_ids, query[\"selected_chunk_id\"])\n",
    "    for retrieved_chunk_ids, query in zip(search_results, test_data)\n",
    "]\n",
    "results[\"Semantic Search\"] = pd.DataFrame(evaluation_metrics).mean()\n",
    "\n",
    "\n",
    "for header_name, model_name in model_names.items():\n",
    "    search_results = cohere_rerank_search(table, test_data, 50, model_name)\n",
    "    evaluation_metrics = [\n",
    "        score(retrieved_chunk_ids, query[\"selected_chunk_id\"])\n",
    "        for retrieved_chunk_ids, query in zip(search_results, test_data)\n",
    "    ]\n",
    "    results[f\"({header_name})\"] = pd.DataFrame(evaluation_metrics).mean()\n",
    "\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Print the table\n",
    "print(tabulate(df.round(2), headers=\"keys\", tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20482164-2802-47be-864d-48134dbf67e4",
   "metadata": {},
   "source": [
    "# Metadata Ingestion\n",
    "\n",
    "We've looked at different ways that we can set up our retrieval pipeline. Let's now switch gears and see how we can experiment with metadata ingestion to improve the quality of our search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34d7a57-9085-431d-98b8-2cef1d4c0e02",
   "metadata": {},
   "source": [
    "## Creating Question-Answer Pairs\n",
    "\n",
    "We previously used Instructor to generate synthethic questions and answers. Let's see how we can expand on this to improve our retrieval pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bf91c53-ffe7-4cba-83ad-d6dc66fe6186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lancedb\n",
    "\n",
    "db = lancedb.connect(\"../lance\")\n",
    "table = db.open_table(\"ms_marco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27bb41ab-0c82-426b-8c5b-388dd7682a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = table.to_pandas()[\"text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "546f7134-a08b-41f0-8eb2-cdcae3e6d04e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Since 2007, the RBA's outstanding reputation has been affected by the 'Securency' or NPA scandal. These RBA subsidiaries were involved in bribing overseas officials so that Australia might win lucrative note-printing contracts. The assets of the bank include the gold and foreign exchange reserves of Australia, which is estimated to have a net worth of A$101 billion. Nearly 94% of the RBA's employees work at its headquarters in Sydney, New South Wales and at the Business Resumption Site.\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now for each chunk, we'll generate a question and answer pair that we'll embed into our database\n",
    "\n",
    "chunk = chunks[0]\n",
    "chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15f4461b-fb4c-494c-a1ca-4a1d5331bee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.49s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'response': QuestionAnswerResponse(chain_of_thought=\"The text chunk highlights the impact of the 'Securency' or NPA scandal on the RBA since 2007, describes the RBA's assets and net worth, and provides information about the employees. A hypothetical user might search for details regarding the scandal, the bank's net worth, or the distribution of its employees. The question and answer pair should therefore focus on these unique aspects of the text.\", question=\"What scandal has affected the RBA's reputation since 2007 and how many of its employees work at the headquarters?\", answer=\"Since 2007, the RBA's outstanding reputation has been affected by the 'Securency' or NPA scandal, which involved bribing overseas officials to win note-printing contracts. Nearly 94% of the RBA's employees work at its headquarters in Sydney, New South Wales, and at the Business Resumption Site.\"),\n",
       "  'source': \"Since 2007, the RBA's outstanding reputation has been affected by the 'Securency' or NPA scandal. These RBA subsidiaries were involved in bribing overseas officials so that Australia might win lucrative note-printing contracts. The assets of the bank include the gold and foreign exchange reserves of Australia, which is estimated to have a net worth of A$101 billion. Nearly 94% of the RBA's employees work at its headquarters in Sydney, New South Wales and at the Business Resumption Site.\"}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lib.synthethic import generate_question_batch\n",
    "\n",
    "question = await generate_question_batch([chunk], 20)\n",
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23659173-a7fa-47c0-b88c-0f3b87e47a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lancedb.pydantic import LanceModel, Vector\n",
    "from lancedb.embeddings import get_registry\n",
    "\n",
    "func = get_registry().get(\"openai\").create(name=\"text-embedding-3-small\")\n",
    "\n",
    "\n",
    "class EmbeddedPassageWithQA(LanceModel):\n",
    "    vector: Vector(func.ndims()) = func.VectorField()\n",
    "    chunk_id: str\n",
    "    text: str = func.SourceField()\n",
    "    source_text: str\n",
    "\n",
    "\n",
    "table_withqa = db.create_table(\n",
    "    \"ms_marco_qa_4\", schema=EmbeddedPassageWithQA, mode=\"overwrite\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70a1c83a-0e6e-42e0-a900-a4f1bfbbfad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████| 1624/1624 [02:26<00:00, 11.12it/s]\n"
     ]
    }
   ],
   "source": [
    "questions = await generate_question_batch(chunks, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "515a8fc6-014e-4398-a5eb-a5cf454604e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"../data/synth-questions-4o.jsonl\", \"w\") as file:\n",
    "    for question in questions:\n",
    "        question_obj = {\n",
    "            \"question\": question[\"response\"].question,\n",
    "            \"answer\": question[\"response\"].answer,\n",
    "            \"chunk\": question[\"source\"],\n",
    "        }\n",
    "        file.write(json.dumps(question_obj) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73603515-aa31-492d-9554-f8ae38c697fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.data import get_labels\n",
    "\n",
    "cached_questions = get_labels(\"../data/synth-questions-4o.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3bf685a-081a-4c7a-ae70-254543634763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [03:15,  1.60s/it]\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "from itertools import batched\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def get_chunks(questions):\n",
    "    for question in questions:\n",
    "        chunk_id = hashlib.md5(question[\"chunk\"].encode()).hexdigest()\n",
    "        yield {\n",
    "            \"chunk_id\": chunk_id,\n",
    "            \"text\": question[\"chunk\"],\n",
    "            \"source_text\": question[\"chunk\"],\n",
    "        }\n",
    "        yield {\n",
    "            \"chunk_id\": chunk_id,\n",
    "            \"text\": question[\"question\"],\n",
    "            \"source_text\": question[\"chunk\"],\n",
    "        }\n",
    "        yield {\n",
    "            \"chunk_id\": chunk_id,\n",
    "            \"text\": question[\"answer\"],\n",
    "            \"source_text\": question[\"chunk\"],\n",
    "        }\n",
    "\n",
    "\n",
    "batches = batched(get_chunks(cached_questions), 40)\n",
    "\n",
    "for batch in tqdm(batches):\n",
    "    table_withqa.add(list(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "010328f4-a327-46de-96f8-7085113ada47",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_withqa.create_fts_index([\"text\", \"source_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d43c456d-2b5e-4a87-9df9-741a53604438",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 6898.53it/s]\n",
      "100%|██████████| 30/30 [00:01<00:00, 21.84it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 18040.02it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 33.34it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 40.45it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 45.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+---------------+----------------+----------------+\n",
      "|           |   SS (With Q) |   SS (W/o  Q) |   FTS (With Q) |   FTS (W/o  Q) |\n",
      "+===========+===============+===============+================+================+\n",
      "| mrr@3     |          0.25 |          0.37 |           0.18 |           0.26 |\n",
      "+-----------+---------------+---------------+----------------+----------------+\n",
      "| mrr@5     |          0.31 |          0.41 |           0.22 |           0.31 |\n",
      "+-----------+---------------+---------------+----------------+----------------+\n",
      "| mrr@10    |          0.34 |          0.43 |           0.26 |           0.34 |\n",
      "+-----------+---------------+---------------+----------------+----------------+\n",
      "| mrr@15    |          0.35 |          0.43 |           0.27 |           0.35 |\n",
      "+-----------+---------------+---------------+----------------+----------------+\n",
      "| mrr@25    |          0.35 |          0.43 |           0.27 |           0.35 |\n",
      "+-----------+---------------+---------------+----------------+----------------+\n",
      "| recall@3  |          0.4  |          0.67 |           0.23 |           0.4  |\n",
      "+-----------+---------------+---------------+----------------+----------------+\n",
      "| recall@5  |          0.67 |          0.9  |           0.43 |           0.67 |\n",
      "+-----------+---------------+---------------+----------------+----------------+\n",
      "| recall@10 |          0.87 |          0.97 |           0.7  |           0.87 |\n",
      "+-----------+---------------+---------------+----------------+----------------+\n",
      "| recall@15 |          0.97 |          1    |           0.87 |           0.9  |\n",
      "+-----------+---------------+---------------+----------------+----------------+\n",
      "| recall@25 |          1    |          1    |           0.93 |           0.93 |\n",
      "+-----------+---------------+---------------+----------------+----------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from lib.data import get_labels\n",
    "from lib.eval import score\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from lib.db import get_table\n",
    "from lib.models import EmbeddedPassageWithQA, EmbeddedPassage\n",
    "from lib.query import full_text_search, semantic_search\n",
    "from itertools import product\n",
    "from tabulate import tabulate\n",
    "\n",
    "test_data = get_labels(\"../data/queries_single_label.jsonl\")[:30]\n",
    "table_withqa = get_table(db, \"ms_marco_qa_4\", EmbeddedPassageWithQA)\n",
    "table = get_table(db, \"ms_marco\", EmbeddedPassage)\n",
    "\n",
    "\n",
    "candidates = {\n",
    "    \"SS\": semantic_search,\n",
    "    \"FTS\": full_text_search,\n",
    "}\n",
    "\n",
    "tables = {\"With Q\": table_withqa, \"W/o  Q\": table}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for (\n",
    "    candidate_fn_tuple,\n",
    "    db_table_tuple,\n",
    ") in product(candidates.items(), tables.items()):\n",
    "    db_name, db_table = db_table_tuple\n",
    "    candidate_name, search_fn = candidate_fn_tuple\n",
    "    search_results = search_fn(db_table, test_data, 25)\n",
    "    evaluation_metrics = [\n",
    "        score(retrieved_chunk_ids, query[\"selected_chunk_id\"])\n",
    "        for retrieved_chunk_ids, query in zip(search_results, test_data)\n",
    "    ]\n",
    "    results[f\"{candidate_name} ({db_name})\"] = pd.DataFrame(evaluation_metrics).mean()\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Print the table\n",
    "print(tabulate(df.round(2), headers=\"keys\", tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c45c5ed1-3c60-4f49-99f3-47a673996408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 5777.28it/s]\n",
      "100%|██████████| 30/30 [00:01<00:00, 23.80it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 11765.23it/s]\n",
      "100%|██████████| 30/30 [00:01<00:00, 29.77it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 33.90it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 43.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------------+---------------+----------------+----------------+\n",
      "|           |   SS (With Q) |   SS (W/o  Q) |   FTS (With Q) |   FTS (W/o  Q) |\n",
      "+===========+===============+===============+================+================+\n",
      "| mrr@3     |          0.27 |          0.39 |           0.21 |           0.3  |\n",
      "+-----------+---------------+---------------+----------------+----------------+\n",
      "| mrr@5     |          0.33 |          0.42 |           0.25 |           0.35 |\n",
      "+-----------+---------------+---------------+----------------+----------------+\n",
      "| mrr@10    |          0.36 |          0.43 |           0.29 |           0.38 |\n",
      "+-----------+---------------+---------------+----------------+----------------+\n",
      "| mrr@15    |          0.37 |          0.44 |           0.31 |           0.38 |\n",
      "+-----------+---------------+---------------+----------------+----------------+\n",
      "| mrr@25    |          0.37 |          0.44 |           0.31 |           0.38 |\n",
      "+-----------+---------------+---------------+----------------+----------------+\n",
      "| recall@3  |          0.4  |          0.7  |           0.27 |           0.45 |\n",
      "+-----------+---------------+---------------+----------------+----------------+\n",
      "| recall@5  |          0.7  |          0.9  |           0.45 |           0.68 |\n",
      "+-----------+---------------+---------------+----------------+----------------+\n",
      "| recall@10 |          0.87 |          0.97 |           0.73 |           0.88 |\n",
      "+-----------+---------------+---------------+----------------+----------------+\n",
      "| recall@15 |          0.97 |          1    |           0.88 |           0.92 |\n",
      "+-----------+---------------+---------------+----------------+----------------+\n",
      "| recall@25 |          1    |          1    |           0.93 |           0.93 |\n",
      "+-----------+---------------+---------------+----------------+----------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from lib.data import get_labels\n",
    "from lib.eval import score\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from lib.db import get_table\n",
    "from lib.models import EmbeddedPassageWithQA, EmbeddedPassage\n",
    "from lib.query import full_text_search, semantic_search\n",
    "from itertools import product\n",
    "from tabulate import tabulate\n",
    "\n",
    "test_data = get_labels(\"../data/queries_multi_label.jsonl\")[:30]\n",
    "table_withqa = get_table(db, \"ms_marco_qa_4\", EmbeddedPassageWithQA)\n",
    "table = get_table(db, \"ms_marco\", EmbeddedPassage)\n",
    "\n",
    "candidates = {\n",
    "    \"SS\": semantic_search,\n",
    "    \"FTS\": full_text_search,\n",
    "}\n",
    "\n",
    "tables = {\"With Q\": table_withqa, \"W/o  Q\": table}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for (\n",
    "    candidate_fn_tuple,\n",
    "    db_table_tuple,\n",
    ") in product(candidates.items(), tables.items()):\n",
    "    db_name, db_table = db_table_tuple\n",
    "    candidate_name, search_fn = candidate_fn_tuple\n",
    "    search_results = search_fn(db_table, test_data, 25)\n",
    "    evaluation_metrics = [\n",
    "        score(retrieved_chunk_ids, query[\"selected_chunk_ids\"])\n",
    "        for retrieved_chunk_ids, query in zip(search_results, test_data)\n",
    "    ]\n",
    "    results[f\"{candidate_name} ({db_name})\"] = pd.DataFrame(evaluation_metrics).mean()\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Print the table\n",
    "print(tabulate(df.round(2), headers=\"keys\", tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "09b633c2-ae27-4e94-ba90-f3be4d7f1217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>text</th>\n",
       "      <th>source_text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9dc539403752581ac234e01d2eb77877</td>\n",
       "      <td>The common species of Taraxacum that rapidly c...</td>\n",
       "      <td>Taraxacum /təˈraeksəkʉm/ təˈræksəkʉm is a larg...</td>\n",
       "      <td>29.076788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9dc539403752581ac234e01d2eb77877</td>\n",
       "      <td>Taraxacum /təˈraeksəkʉm/ təˈræksəkʉm is a larg...</td>\n",
       "      <td>Taraxacum /təˈraeksəkʉm/ təˈræksəkʉm is a larg...</td>\n",
       "      <td>28.786659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9dc539403752581ac234e01d2eb77877</td>\n",
       "      <td>What is the common species of Taraxacum that r...</td>\n",
       "      <td>Taraxacum /təˈraeksəkʉm/ təˈræksəkʉm is a larg...</td>\n",
       "      <td>22.830486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            chunk_id  \\\n",
       "0   9dc539403752581ac234e01d2eb77877   \n",
       "1   9dc539403752581ac234e01d2eb77877   \n",
       "11  9dc539403752581ac234e01d2eb77877   \n",
       "\n",
       "                                                 text  \\\n",
       "0   The common species of Taraxacum that rapidly c...   \n",
       "1   Taraxacum /təˈraeksəkʉm/ təˈræksəkʉm is a larg...   \n",
       "11  What is the common species of Taraxacum that r...   \n",
       "\n",
       "                                          source_text      score  \n",
       "0   Taraxacum /təˈraeksəkʉm/ təˈræksəkʉm is a larg...  29.076788  \n",
       "1   Taraxacum /təˈraeksəkʉm/ təˈræksəkʉm is a larg...  28.786659  \n",
       "11  Taraxacum /təˈraeksəkʉm/ təˈræksəkʉm is a larg...  22.830486  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_withqa = get_table(db, \"ms_marco_qa_4\", EmbeddedPassageWithQA)\n",
    "desired_result = \"9dc539403752581ac234e01d2eb77877\"\n",
    "queried_results = (\n",
    "    table_withqa.search(\"what species is a dandelion\", query_type=\"fts\")\n",
    "    .select([\"chunk_id\", \"text\", \"source_text\"])\n",
    "    .limit(20)\n",
    "    .to_pandas()\n",
    ")\n",
    "queried_results[queried_results[\"chunk_id\"] == \"9dc539403752581ac234e01d2eb77877\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "73d8d2f1-09fa-436d-9a17-e5271e32d82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9dc539403752581ac234e01d2eb77877</td>\n",
       "      <td>Taraxacum /təˈraeksəkʉm/ təˈræksəkʉm is a larg...</td>\n",
       "      <td>14.361879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89c9edbed59513ee50cb83e1cfb1ebbe</td>\n",
       "      <td>Taraxacum /təˈraeksəkʉm/ təˈræksəkʉm is a larg...</td>\n",
       "      <td>14.211342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>591eae9a842ee783b157f2b033519a2e</td>\n",
       "      <td>Both species are edible in their entirety. The...</td>\n",
       "      <td>13.762878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0853e1b91ecae08717962457740453fa</td>\n",
       "      <td>Description. There are considered to be about ...</td>\n",
       "      <td>13.485062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ea830e20c43da3d767c180fee0f061de</td>\n",
       "      <td>About this species. Dandelions are well-known,...</td>\n",
       "      <td>13.234418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>a75f014e6c6f31495e04f78e8476b54d</td>\n",
       "      <td>Plant Description. Hundreds of species of dand...</td>\n",
       "      <td>12.953527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>a5872798dffbe3077255ed0dd0dd7a12</td>\n",
       "      <td>Each single flower in a head is called a flore...</td>\n",
       "      <td>12.775234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>c97bb0fb297bff6c2ea72c07962cf198</td>\n",
       "      <td>The common name Dandelion is given to members ...</td>\n",
       "      <td>9.375005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8f3042881945d16694e29a710681255e</td>\n",
       "      <td>Level 3 Bonding can be described as a biologic...</td>\n",
       "      <td>6.272810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>f982e5c138dc4c59c837a71a577de593</td>\n",
       "      <td>While you’ll never hear me use the phrase “It ...</td>\n",
       "      <td>5.874215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>a1525d8875d21362a93a0b853ab0b747</td>\n",
       "      <td>What to Write in a Get Well Card. Writing a ge...</td>\n",
       "      <td>5.733679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6cba2875bd4c442c0e70b28a49997100</td>\n",
       "      <td>The contraction of you are is you're. An abbre...</td>\n",
       "      <td>5.709448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3834aed990caad2ec860d6231952760c</td>\n",
       "      <td>Asian Carp Fact Sheet. 1  Asian carp are a typ...</td>\n",
       "      <td>5.658959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>860ad67d9b438ab31ad58cfa8297b2a9</td>\n",
       "      <td>A skiing ability level is a short way of class...</td>\n",
       "      <td>5.591760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8bd64761d127bdd0bd78fa3d78b338b2</td>\n",
       "      <td>The following list of marine aquarium fish spe...</td>\n",
       "      <td>5.550859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8a4cd6c241153beb1ee4b6ac7852edea</td>\n",
       "      <td>Related Questions. Who first coined the phrase...</td>\n",
       "      <td>5.541169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>94af542b34a96384e9258c490c53236a</td>\n",
       "      <td>Habits: Damselfish are found in all tropical a...</td>\n",
       "      <td>5.515049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>9974d0c1b0e9b2615b14e6ecc2dfe02a</td>\n",
       "      <td>For example Ave. stands for Avenue and Apt. st...</td>\n",
       "      <td>5.502489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2a524117c818bd1b4b1d8dca9d769cd8</td>\n",
       "      <td>These fascinating creatures (Limulus polyphemu...</td>\n",
       "      <td>5.462506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>058c01c0e027e3061acd37ddde128424</td>\n",
       "      <td>Carp are various species of oily freshwater fi...</td>\n",
       "      <td>5.431587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            chunk_id  \\\n",
       "0   9dc539403752581ac234e01d2eb77877   \n",
       "1   89c9edbed59513ee50cb83e1cfb1ebbe   \n",
       "2   591eae9a842ee783b157f2b033519a2e   \n",
       "3   0853e1b91ecae08717962457740453fa   \n",
       "4   ea830e20c43da3d767c180fee0f061de   \n",
       "5   a75f014e6c6f31495e04f78e8476b54d   \n",
       "6   a5872798dffbe3077255ed0dd0dd7a12   \n",
       "7   c97bb0fb297bff6c2ea72c07962cf198   \n",
       "8   8f3042881945d16694e29a710681255e   \n",
       "9   f982e5c138dc4c59c837a71a577de593   \n",
       "10  a1525d8875d21362a93a0b853ab0b747   \n",
       "11  6cba2875bd4c442c0e70b28a49997100   \n",
       "12  3834aed990caad2ec860d6231952760c   \n",
       "13  860ad67d9b438ab31ad58cfa8297b2a9   \n",
       "14  8bd64761d127bdd0bd78fa3d78b338b2   \n",
       "15  8a4cd6c241153beb1ee4b6ac7852edea   \n",
       "16  94af542b34a96384e9258c490c53236a   \n",
       "17  9974d0c1b0e9b2615b14e6ecc2dfe02a   \n",
       "18  2a524117c818bd1b4b1d8dca9d769cd8   \n",
       "19  058c01c0e027e3061acd37ddde128424   \n",
       "\n",
       "                                                 text      score  \n",
       "0   Taraxacum /təˈraeksəkʉm/ təˈræksəkʉm is a larg...  14.361879  \n",
       "1   Taraxacum /təˈraeksəkʉm/ təˈræksəkʉm is a larg...  14.211342  \n",
       "2   Both species are edible in their entirety. The...  13.762878  \n",
       "3   Description. There are considered to be about ...  13.485062  \n",
       "4   About this species. Dandelions are well-known,...  13.234418  \n",
       "5   Plant Description. Hundreds of species of dand...  12.953527  \n",
       "6   Each single flower in a head is called a flore...  12.775234  \n",
       "7   The common name Dandelion is given to members ...   9.375005  \n",
       "8   Level 3 Bonding can be described as a biologic...   6.272810  \n",
       "9   While you’ll never hear me use the phrase “It ...   5.874215  \n",
       "10  What to Write in a Get Well Card. Writing a ge...   5.733679  \n",
       "11  The contraction of you are is you're. An abbre...   5.709448  \n",
       "12  Asian Carp Fact Sheet. 1  Asian carp are a typ...   5.658959  \n",
       "13  A skiing ability level is a short way of class...   5.591760  \n",
       "14  The following list of marine aquarium fish spe...   5.550859  \n",
       "15  Related Questions. Who first coined the phrase...   5.541169  \n",
       "16  Habits: Damselfish are found in all tropical a...   5.515049  \n",
       "17  For example Ave. stands for Avenue and Apt. st...   5.502489  \n",
       "18  These fascinating creatures (Limulus polyphemu...   5.462506  \n",
       "19  Carp are various species of oily freshwater fi...   5.431587  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = get_table(db, \"ms_marco\", EmbeddedPassageWithQA)\n",
    "\n",
    "desired_result = \"9dc539403752581ac234e01d2eb77877\"\n",
    "queried_results = (\n",
    "    table.search(\"what species is a dandelion\", query_type=\"fts\")\n",
    "    .select([\"chunk_id\", \"text\"])\n",
    "    .limit(20)\n",
    "    .to_pandas()\n",
    ")\n",
    "# queried_results[queried_results['chunk_id'] == '9dc539403752581ac234e01d2eb77877']\n",
    "queried_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf14a2b-cfdd-4670-a340-79a4c8fb0151",
   "metadata": {},
   "source": [
    "## Creating Metadata using GPT4-o \n",
    "\n",
    "Now that we've seen how to create synthethic questions, let's try looking at another method of improving our search pipeline - creating metadata when ingesting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31747560-d7b3-4d56-8501-751512139b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Metadata(keywords=['RBA', 'outstanding reputation', 'Securency', 'NPA scandal', 'subsidairies', 'bribing', 'note-printing contracts', 'assets', 'gold reserves', 'foreign exchange reserves', 'net worth', 'A$101 billion', 'employees', 'headquarters', 'Sydney', 'Business Resumption Site'], hypothetical_phrases=['RBA scandal', 'Australia note-printing contracts', 'RBA assets', 'RBA employees', 'RBA headquarters'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import instructor\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "client = instructor.from_openai(OpenAI())\n",
    "\n",
    "class Metadata(BaseModel):\n",
    "    \"\"\"\n",
    "    This is a model which represents some metadata that we want to generate from a given text. \n",
    "    \n",
    "    Make sure to expand on the text by extracting out any accronyms, context or phrases that users might search for later on \\\n",
    "    when trying to retrieve this specific chunk and model the metadata in a way that allows us to retrieve the most relevant chunks when searching for the query\n",
    "    \"\"\"\n",
    "\n",
    "    keywords: list[str] = Field(\n",
    "        ...,\n",
    "        description=\"This is a field which represents keywords that a user might use to search for this text\",\n",
    "    )\n",
    "    hypothetical_phrases: list[str] = Field(\n",
    "        ...,\n",
    "        description=\"This is a field which represents hypothetical phrases that a user might use to search for this text\",\n",
    "    )\n",
    "\n",
    "\n",
    "def enhance_query(text_chunk: str):\n",
    "    return client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        response_model=Metadata,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a world class query indexing system. You are about to be passed a text chunk and you'll need to generate some metadata that will allow you to retrieve this specific chunk when the user makes a relevant query\",\n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": f\"The text chunk is {text_chunk}\"},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "enhance_query(\"Since 2007, the RBA's outstanding reputation has been affected by the 'Securency' or NPA scandal. These RBA subsidiaries were involved in bribing overseas officials so that Australia might win lucrative note-printing contracts. The assets of the bank include the gold and foreign exchange reserves of Australia, which is estimated to have a net worth of A$101 billion. Nearly 94% of the RBA's employees work at its headquarters in Sydney, New South Wales and at the Business Resumption Site.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03a4ef03",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': Metadata(keywords=['RBA', 'outstanding reputation', 'Securency scandal', 'NPA scandal', 'bribing', 'overseas officials', 'note-printing contracts', 'gold reserves', 'foreign exchange reserves', 'net worth', 'A$101 billion', 'employees', 'Sydney', 'New South Wales', 'Business Resumption Site'], hypothetical_phrases=['RBA scandal', 'bank assets', 'RBA headquarters', 'Australia reserves', 'RBA employees']), 'source': \"Since 2007, the RBA's outstanding reputation has been affected by the 'Securency' or NPA scandal. These RBA subsidiaries were involved in bribing overseas officials so that Australia might win lucrative note-printing contracts. The assets of the bank include the gold and foreign exchange reserves of Australia, which is estimated to have a net worth of A$101 billion. Nearly 94% of the RBA's employees work at its headquarters in Sydney, New South Wales and at the Business Resumption Site.\"}\n",
      "{'response': Metadata(keywords=['Reserve Bank of Australia', 'RBA', 'central bank', 'banknote issuing authority', 'Reserve Bank Act 1959', 'Commonwealth Bank', 'gold reserves', 'foreign exchange reserves', 'net worth', 'Sydney', 'New South Wales', 'Business Resumption Site'], hypothetical_phrases=['When was the Reserve Bank of Australia established?', 'What are the assets of the Reserve Bank of Australia?', \"Where do most of the RBA's employees work?\"]), 'source': \"The Reserve Bank of Australia (RBA) came into being on 14 January 1960 as Australia 's central bank and banknote issuing authority, when the Reserve Bank Act 1959 removed the central banking functions from the Commonwealth Bank. The assets of the bank include the gold and foreign exchange reserves of Australia, which is estimated to have a net worth of A$101 billion. Nearly 94% of the RBA's employees work at its headquarters in Sydney, New South Wales and at the Business Resumption Site.\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from lib.synthethic import generate_metadata_batch\n",
    "import lancedb\n",
    "\n",
    "db = lancedb.connect(\"../lance\")\n",
    "table = db.open_table(\"ms_marco\")\n",
    "\n",
    "\n",
    "chunks = table.to_pandas()[\"text\"].tolist()\n",
    "res = await generate_metadata_batch(chunks[:2], 20)\n",
    "for item in res:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d533083f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1624 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1624/1624 [00:57<00:00, 28.47it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels saved to ../data/synth-metadata-gpt3.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from lib.data import save_labels\n",
    "import json\n",
    "\n",
    "metadata_batch = await generate_metadata_batch(chunks, 20)\n",
    "\n",
    "data = []\n",
    "\n",
    "for metadata in metadata_batch:\n",
    "    response_data = json.loads(metadata[\"response\"].model_dump_json())\n",
    "\n",
    "    data.append({\"source\": metadata[\"source\"], **response_data})\n",
    "\n",
    "save_labels(data, \"../data/synth-metadata-gpt3.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c40b45f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'source': \"Since 2007, the RBA's outstanding reputation has been affected by the 'Securency' or NPA scandal. These RBA subsidiaries were involved in bribing overseas officials so that Australia might win lucrative note-printing contracts. The assets of the bank include the gold and foreign exchange reserves of Australia, which is estimated to have a net worth of A$101 billion. Nearly 94% of the RBA's employees work at its headquarters in Sydney, New South Wales and at the Business Resumption Site.\", 'keywords': ['RBA', 'Securency', 'NPA scandal', 'bribery', 'note-printing contracts', 'gold reserves', 'foreign exchange reserves', 'net worth', 'Sydney', 'New South Wales', 'Business Resumption Site'], 'hypothetical_phrases': ['RBA outstanding reputation', 'RBA subsidiaries scandal', 'Australia note-printing contracts', 'RBA assets', 'RBA headquarters Sydney', 'RBA employees']}, {'source': \"The Reserve Bank of Australia (RBA) came into being on 14 January 1960 as Australia 's central bank and banknote issuing authority, when the Reserve Bank Act 1959 removed the central banking functions from the Commonwealth Bank. The assets of the bank include the gold and foreign exchange reserves of Australia, which is estimated to have a net worth of A$101 billion. Nearly 94% of the RBA's employees work at its headquarters in Sydney, New South Wales and at the Business Resumption Site.\", 'keywords': ['Reserve Bank of Australia', 'RBA', 'central bank', 'banknote issuing authority', 'Reserve Bank Act 1959', 'Commonwealth Bank'], 'hypothetical_phrases': ['Australia central bank', 'RBA headquarters', 'gold reserves of Australia', 'foreign exchange reserves', 'RBA employees', 'Business Resumption Site']}]\n"
     ]
    }
   ],
   "source": [
    "from lib.data import get_labels\n",
    "\n",
    "data = get_labels(\"../data/synth-metadata-gpt3.jsonl\")\n",
    "print(data[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf32631b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lancedb\n",
    "from lancedb.pydantic import LanceModel, Vector\n",
    "from lancedb.embeddings import get_registry\n",
    "\n",
    "func = get_registry().get(\"openai\").create(name=\"text-embedding-3-small\")\n",
    "\n",
    "db = lancedb.connect(\"../lance\")\n",
    "\n",
    "\n",
    "class EmbeddedPassageWithMetadata(LanceModel):\n",
    "    vector: Vector(func.ndims()) = func.VectorField()\n",
    "    chunk_id: str\n",
    "    text: str = func.SourceField()\n",
    "    keywords: str\n",
    "    search_queries: str\n",
    "\n",
    "table_with_metadata = db.create_table(\n",
    "    \"ms_marco_metadata\", schema=EmbeddedPassageWithMetadata, mode=\"overwrite\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7f3756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:02<00:00,  4.35it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'response': Metadata(keywords=['RBA', 'Securency', 'NPA scandal', 'Australia', 'gold reserves', 'foreign exchange reserves', 'Sydney', 'New South Wales', 'Business Resumption Site'], hypothetical_phrases=['RBA outstanding reputation', 'bribing overseas officials', 'note-printing contracts', 'net worth of A$101 billion', 'RBA headquarters', 'RBA employees']),\n",
       "  'source': \"Since 2007, the RBA's outstanding reputation has been affected by the 'Securency' or NPA scandal. These RBA subsidiaries were involved in bribing overseas officials so that Australia might win lucrative note-printing contracts. The assets of the bank include the gold and foreign exchange reserves of Australia, which is estimated to have a net worth of A$101 billion. Nearly 94% of the RBA's employees work at its headquarters in Sydney, New South Wales and at the Business Resumption Site.\"},\n",
       " {'response': Metadata(keywords=['Reserve Bank of Australia', 'RBA', 'central bank', 'banknote issuing authority', 'Reserve Bank Act 1959', 'Commonwealth Bank', 'gold reserves', 'foreign exchange reserves', 'net worth', 'employees', 'Sydney', 'New South Wales', 'Business Resumption Site'], hypothetical_phrases=['Australia central bank', 'RBA establishment', 'banknote issuing', 'gold and foreign exchange reserves', 'RBA headquarters', 'Sydney employees', 'Reserve Bank Act 1959']),\n",
       "  'source': \"The Reserve Bank of Australia (RBA) came into being on 14 January 1960 as Australia 's central bank and banknote issuing authority, when the Reserve Bank Act 1959 removed the central banking functions from the Commonwealth Bank. The assets of the bank include the gold and foreign exchange reserves of Australia, which is estimated to have a net worth of A$101 billion. Nearly 94% of the RBA's employees work at its headquarters in Sydney, New South Wales and at the Business Resumption Site.\"},\n",
       " {'response': Metadata(keywords=['RBA', '2014 Microsoft US Regional Partner', 'PR Newswire', 'Contract Awarded', 'Securitisations System', 'Risk Management', 'Analysis'], hypothetical_phrases=['RBA Recognized', 'PR Newswire Contract Award', '2014 Microsoft Partner', 'Securitisations System Support', 'Risk Management System']),\n",
       "  'source': 'RBA Recognized with the 2014 Microsoft US Regional Partner of the ... by PR Newswire. Contract Awarded for supply and support the. Securitisations System used for risk management and analysis. '},\n",
       " {'response': Metadata(keywords=['rebuildable atomizer', 'RBA', 'coil', 'Kanthal', 'nichrome', 'current', 'eliquid', 'bottom feed RBA', 'bottom coil clearomizer', 'cotton wick', 'silica wick', 'Genesis', 'genny', 'mesh wire'], hypothetical_phrases=['inner workings of rebuildable atomizer', 'coil heating process', 'bottom feed RBA advantages', 'cotton vs silica wick', 'Genesis RBA']),\n",
       "  'source': 'The inner workings of a rebuildable atomizer are surprisingly simple. The coil inside the RBA is made of some type of resistance wire, normally Kanthal or nichrome. When a current is applied to the coil (resistance wire), it heats up and the heated coil then vaporizes the eliquid. 1 The bottom feed RBA is, perhaps, the easiest of all RBA types to build, maintain, and use. 2  It is filled from below, much like bottom coil clearomizer. 3  Bottom feed RBAs can utilize cotton instead of silica for the wick. 4  The Genesis, or genny, is a top feed RBA that utilizes a short woven mesh wire.'},\n",
       " {'response': Metadata(keywords=['Results-Based Accountability', 'RBA', 'improve lives', 'youth', 'families', 'adults', 'community', 'organizations', 'programs', 'talk to action', 'common sense process', 'assumptions', 'innovation'], hypothetical_phrases=['disciplined way of thinking', 'taking action', 'improve performance', 'surface assumptions', 'challenge barriers to innovation']),\n",
       "  'source': 'Results-Based Accountability® (also known as RBA) is a disciplined way of thinking and taking action that communities can use to improve the lives of children, youth, families, adults and the community as a whole. RBA is also used by organizations to improve the performance of their programs. RBA improves the lives of children, families, and communities and the performance of programs because RBA: 1  Gets from talk to action quickly; 2  Is a simple, common sense process that everyone can understand; 3  Helps groups to surface and challenge assumptions that can be barriers to innovation;'},\n",
       " {'response': Metadata(keywords=['Results-Based Accountability', 'RBA', 'improve lives', 'children', 'youth', 'families', 'adults', 'community', 'organizations', 'programs', 'Community Impact', 'conditions of well-being', 'leaders', 'Residents with good jobs', 'Children ready for school', 'safe and clean neighborhood'], hypothetical_phrases=['disciplined way of thinking', 'taking action', 'improve performance', 'creating community impact', 'well-being for children', 'leaders working collectively to improve']),\n",
       "  'source': 'Results-Based Accountability® (also known as RBA) is a disciplined way of thinking and taking action that communities can use to improve the lives of children, youth, families, adults and the community as a whole. RBA is also used by organizations to improve the performance of their programs. Creating Community Impact with RBA. Community impact focuses on conditions of well-being for children, families and the community as a whole that a group of leaders is working collectively to improve. For example: “Residents with good jobs,” “Children ready for school,” or “A safe and clean neighborhood”.'},\n",
       " {'response': Metadata(keywords=['RBA', 'data-driven decision-making', 'community', 'organization', 'solve problems', 'framework', 'ends and means', 'children', 'families', 'communities', 'programs', 'action', 'assumptions', 'innovation'], hypothetical_phrases=['RBA decision-making process', 'data-driven approach', 'community problem-solving', 'organization framework', 'RBA benefits for children and families', 'assumptions in decision-making']),\n",
       "  'source': 'RBA uses a data-driven, decision-making process to help communities and organizations get beyond talking about problems to taking action to solve problems. It is a simple, common sense framework that everyone can understand. RBA starts with ends and works backward, towards means. The “end” or difference you are trying to make looks slightly different if you are working on a broad community level or are focusing on your specific program or organization. RBA improves the lives of children, families, and communities and the performance of programs because RBA: 1  Gets from talk to action quickly; 2  Is a simple, common sense process that everyone can understand; 3  Helps groups to surface and challenge assumptions that can be barriers to innovation;'},\n",
       " {'response': Metadata(keywords=['NetIQ Identity Manager', 'Risk-based authentication', 'RBA', 'user-dependent', 'transaction-dependent', 'authentication processes'], hypothetical_phrases=['vs. NetIQ Identity Manager', 'varying levels of stringency', 'likelihood of compromise', 'RBA categorization', 'user-dependent processes', 'transaction-dependent processes', 'exact credentials']),\n",
       "  'source': 'vs. NetIQ Identity Manager. Risk-based authentication (RBA) is a method of applying varying levels of stringency to authentication processes based on the likelihood that access to a given system could result in its being compromised. Risk-based authentication can be categorized as either user-dependent or transaction-dependent. User-dependent RBA processes employ the same authentication for every session initiated by a given user; the exact credentials that the site demands depend on who the user is.'},\n",
       " {'response': Metadata(keywords=['rebuildable atomizer', 'RBA', 'vape pen', 'mod industry', 'personal vaporizer', 'bottom feed RBA', 'bottom coil clearomizer', 'cotton wick', 'Genesis', 'genny', 'top feed RBA', 'woven mesh wire'], hypothetical_phrases=['special type of atomizer', 'rebuildable', 'bottom feed RBA', 'easy to build', 'maintain', 'fill from below', 'utilize cotton wick', 'top feed RBA', 'short woven mesh wire']),\n",
       "  'source': 'A rebuildable atomizer (RBA), often referred to as simply a “rebuildable,” is just a special type of atomizer used in the Vape Pen and Mod Industry that connects to a personal vaporizer. 1 The bottom feed RBA is, perhaps, the easiest of all RBA types to build, maintain, and use. 2  It is filled from below, much like bottom coil clearomizer. 3  Bottom feed RBAs can utilize cotton instead of silica for the wick. 4  The Genesis, or genny, is a top feed RBA that utilizes a short woven mesh wire.'},\n",
       " {'response': Metadata(keywords=['RBA', 'digital consultancy', 'technology consultancy', 'strategy', 'design', 'technology engineering'], hypothetical_phrases=['digital and technology consultancy', 'progressive companies', 'modern digital experiences']),\n",
       "  'source': 'Get To Know Us. RBA is a digital and technology consultancy with roots in strategy, design and technology. Our team of specialists help progressive companies deliver modern digital experiences backed by proven technology engineering. '}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from lib.synthethic import generate_metadata_batch\n",
    "\n",
    "db = lancedb.connect(\"../lance\")\n",
    "table = db.open_table(\"ms_marco\")\n",
    "\n",
    "\n",
    "chunks = table.to_pandas()[\"text\"].tolist()\n",
    "await generate_metadata_batch(chunks[:10],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a7cf676",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "82it [01:45,  1.29s/it]\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "from itertools import batched\n",
    "from tqdm import tqdm\n",
    "\n",
    "def format_metadata(metadata):\n",
    "    return {\n",
    "        \"chunk_id\": hashlib.md5(metadata[\"source\"].encode()).hexdigest(),\n",
    "        \"text\": metadata[\"source\"],\n",
    "        \"keywords\": \",\".join(metadata[\"keywords\"]),\n",
    "        \"search_queries\": \",\".join(metadata[\"hypothetical_phrases\"]),\n",
    "    }\n",
    "\n",
    "def metadata_generator(metadata_batch):\n",
    "    for metadata in metadata_batch:\n",
    "        yield format_metadata(metadata)\n",
    "\n",
    "metadata_batch = batched(metadata_generator(data), 20)\n",
    "\n",
    "for item in tqdm(metadata_batch):\n",
    "    table_with_metadata.add(list(item))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "593a5666",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_with_metadata.create_fts_index([\"text\",\"keywords\",\"search_queries\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5fb9934",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:02<00:00, 25.79it/s]\n",
      "100%|██████████| 60/60 [00:01<00:00, 39.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------------------+-----------------------+\n",
      "|           |   FTS (With Metadata) |   FTS (W/o  Metadata) |\n",
      "+===========+=======================+=======================+\n",
      "| mrr@3     |                 0.344 |                 0.339 |\n",
      "+-----------+-----------------------+-----------------------+\n",
      "| mrr@5     |                 0.399 |                 0.387 |\n",
      "+-----------+-----------------------+-----------------------+\n",
      "| mrr@10    |                 0.428 |                 0.415 |\n",
      "+-----------+-----------------------+-----------------------+\n",
      "| mrr@15    |                 0.429 |                 0.418 |\n",
      "+-----------+-----------------------+-----------------------+\n",
      "| mrr@25    |                 0.432 |                 0.419 |\n",
      "+-----------+-----------------------+-----------------------+\n",
      "| recall@3  |                 0.5   |                 0.517 |\n",
      "+-----------+-----------------------+-----------------------+\n",
      "| recall@5  |                 0.733 |                 0.733 |\n",
      "+-----------+-----------------------+-----------------------+\n",
      "| recall@10 |                 0.917 |                 0.917 |\n",
      "+-----------+-----------------------+-----------------------+\n",
      "| recall@15 |                 0.933 |                 0.95  |\n",
      "+-----------+-----------------------+-----------------------+\n",
      "| recall@25 |                 0.983 |                 0.967 |\n",
      "+-----------+-----------------------+-----------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from lib.data import get_labels\n",
    "from lib.eval import score\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from lib.db import get_table\n",
    "from lib.models import EmbeddedPassageWithQA, EmbeddedPassage,EmbeddedPassageWithMetadata\n",
    "from lib.query import full_text_search, semantic_search\n",
    "from itertools import product\n",
    "from tabulate import tabulate\n",
    "\n",
    "test_data = get_labels(\"../data/queries_single_label.jsonl\")[:60]\n",
    "table_withqa = get_table(db,\"ms_marco_metadata\", EmbeddedPassageWithMetadata)\n",
    "table = get_table(db, \"ms_marco\", EmbeddedPassage)\n",
    "\n",
    "candidates = {\n",
    "    \"FTS\": full_text_search,\n",
    "}\n",
    "\n",
    "tables = {\"With Metadata\": table_withqa, \"W/o  Metadata\": table}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for (\n",
    "    candidate_fn_tuple,\n",
    "    db_table_tuple,\n",
    ") in product(candidates.items(), tables.items()):\n",
    "    db_name, db_table = db_table_tuple\n",
    "    candidate_name, search_fn = candidate_fn_tuple\n",
    "    search_results = search_fn(db_table, test_data, 25)\n",
    "    evaluation_metrics = [\n",
    "        score(retrieved_chunk_ids, query[\"selected_chunk_id\"])\n",
    "        for retrieved_chunk_ids, query in zip(search_results, test_data)\n",
    "    ]\n",
    "    results[f\"{candidate_name} ({db_name})\"] = pd.DataFrame(evaluation_metrics).mean()\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Print the table\n",
    "print(tabulate(df.round(3), headers=\"keys\", tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f7c2b2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
